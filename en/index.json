[{"content":"","date":null,"permalink":"/en/tags/android/","section":"Tags","summary":"","title":"Android"},{"content":" We know that the screen displays content by emitting RGB lamp beads one by one, and the brightness of the lamp beads is determined by a memory area. By writing data to this memory area, we can observe the data display effect on the screen. This is a complex and flexible job. In order to facilitate this work, the pioneers developed the OpenGL standard, and our story will start from here.\nOpenGL ES #OpenGL ES is a streamlined version of OpenGL. The Android platform has provided support for OpenGL ES since its release. However, different versions support different OpenGL ES versions. The current mainstream versions are still 2.0 and 3.0. OpenGL ES is a set of APIs that provide developers with the ability to configure data, transfer data, and draw content. Its work is strictly related to drawing, so OpenGL ES alone will not cause a big obstacle to understanding. The problem lies in the configuration environment for configuring OpenGL ES. Why should we separate the OpenGL ES API and the configuration environment? Because OpenGL ES is a cross-platform API, but it needs to be bound to a specific platform, such as Android, for actual operation. The conditions required to prepare the OpenGL ES environment are different between platforms. In order to ensure the cross-platform capabilities of OpenGL ES, it is necessary to separate the configuration environment and bind it to a specific platform. On Android, this configuration environment is EGL. Clarifying the difference between the OpenGL ES API and configuring the OpenGL ES environment is not only very helpful in understanding these two key concepts, but also greatly helps in debugging the code and troubleshooting later.\nWorkflow #After clarifying some basic concepts, our next most important task is to clarify the workflow of OpenGL ES. Many tutorials start by listing a lot of nouns or giving examples directly, which I think is inappropriate. Only by becoming familiar with the workflow can we know what to do when writing code and locate problems faster and more accurately during debugging.\nPrepare environment #OpenGL ES is composed of a series of APIs, but it does not mean that these APIs can be called at any time. Instead, it requires some settings in the running environment, which is the preparation environment. Preparing the environment usually involves doing some video memory allocation and window configuration work, which is very tedious but essential.\nPrepare shader #Shaders are very important, but for beginners, you don’t need to pay too much attention to them. Many effects can be directly found in ready-made codes online, but how to assemble these codes into a complete runnable program is not necessarily known. . We just need to be clear that shaders are an important part of OpenGL ES development, and this is where the magic happens.\nPrepare program #Although shaders are important, they cannot run independently and need to be managed by a program. The program in question is an OpenGL ES object that is responsible for putting the shaders together. This object is required before running most OpenGL ES APIs.\nrendering #The rendering process is actually preparing data. We need to assign some data used in the shader, and then call the drawing API to complete the final drawing work. The GPU will pass the data to the shader, and the shader will go through the pipeline to convert the data into final display data and store it in the video memory.\nDisplay #Rendering does not mean that the data is displayed, but that the data is calculated. To see the calculated data on the screen, you may need to call a function in the OpenGL ES environment configuration tool, such as exchanging buffers or switching display objects.\nClean up #Like memory, we will also apply for some resources when using the OpenGL ES API. After rendering, we should actively release the resources for subsequent program use. Many times when our normal application for resources fails, it may be because the previous resources have not been released.\nThe above is the general process for developing OpenGL ES applications. Since OpenGL ES development is difficult to debug, the most effective way to locate problems when discovering them is to determine the error link and then deal with it in a targeted manner. So it’s important to be familiar with the process.\nGet started with examples #Since there are many concepts related to OpenGLES, in order to minimize the interference of related concepts, this article intends to focus on only the first step in the above process. At the same time, use the knowledge points involved to implement a minimal example-dye the window red.\nLet’s start with the first concept—EGL.\nEGL #OpenGL ES is only an abstraction of drawing and does not provide an abstraction of the running environment. If you want to apply for video memory, you need to specify where the video is stored. After the image is calculated, you also need to specify where it will be displayed. EGL is a collection of these environmental abstractions. In order to explain the relevant concepts in a popular way, we can play a role-playing role-what should we do if we are asked to design relevant standards.\nThe first thing that is easy to think of is that we need a monitor, because OpenGL ES will eventually generate a set of color data. If we want to see these colors, we definitely need a monitor to display these color data. At the same time, we know that monitors also have many specifications and features. In order to be compatible with various low-end to high-end monitors, it is definitely necessary to make a layer of abstraction for it and provide some methods for setting properties. This is EGLDisplay\u0026rsquo;s task.\nAfter determining the display, we will find that we can only select the entire display or not use it every time. When we actually use it, there must be situations where only one area is displayed, or multiple areas are displayed at the same time. In order to meet this usage scenario , it is necessary to further divide the display so that it can support the simultaneous operation of multiple areas, and the person responsible for this layer of abstraction task is EGLSurface .\nSince they all support multiple areas, it must be possible to configure the areas. Maybe on the same monitor, one area only needs to display black and white pixels, and another area needs to display high-definition pictures. In order to make these configurations effective and independent of each other, An abstraction is definitely needed, which must be able to save the display configuration and isolate the OpenGL ES environment so that API calls to OpenGL ES in one area will not affect another area. This is EGLContext .\nThe above are the three core concepts of EGL, which are the abstraction of the display, display area, and display configuration.\nThe above concepts are all scattered, and we definitely need to connect all the parts together in actual work, so it is necessary to make a summary of their work processes. First we need to obtain a EGLDisplay to determine the final display device, and then configure a display area EGLSurface according to the configuration supported by the display device. Finally, use EGLContext to connect EGLDisplay and EGLSurface . Once the association is successful, it means that the OpenGL ES environment is ready. The next step is to create a shader, create a shader program, and prepare for drawing.\nAfter sorting out the process, let\u0026rsquo;s take a look at how to write the code. In order to minimize the barriers to understanding, this article will use the Java-side interface as an example.\nPrepare EGLDisplay #Learning any new skill requires an entrance, and the common entrances for OpenGLES and EGL are EGLDisplay . So the first step is to get a EGLDisplay object. We cannot create this object directly, but need to obtain an object through the eglGetDisplay method. This object is very important and is the first parameter of almost all subsequent EGL-related APIs. Therefore, it usually needs to be cached for subsequent use. Although the EGLDisplay object already exists, it cannot be used directly. Need to call eglInitialize for initialization. This phenomenon is also very common in many SDKs. After obtaining the object, it needs to be initialized to ensure that the internal state is restored to the initial state.\nGet configuration #After successfully calling the eglInitialize method, the EGLDisplay object is ready and the display area can be configured. But we don’t know which configuration information is valid and which configuration information is supported, because different hardware supports different features. If we directly hard-code the configuration regardless of the hardware features, the code may fail to run on a certain device. This is not What we want to see. Therefore, in order for the configuration to be valid on all devices, the effective way is not for us to specify the configuration, but for us to actively query the hardware to see if it is the configuration we want, that is, let the EGLDisplay object tell us.\nEGLDisplay provides two methods to query the configuration supported by the hardware. One is to directly obtain all configuration information supported by the device eglGetConfigs , and the other is for the developer to list the desired configuration. Then actively query whether the device supports the listed configurations eglChooseConfig . Developers can choose any method to determine the configuration items of the display area. If the method call is successful, it is equivalent to determining the configuration items of the display area, and we can use these configuration items to configure EGLSurface .\nConfigure display area #Surface is used on the Android platform to represent the display area, but usually we do not deal directly with Surface , but use SurfaceView . However, there are limitations to using SurfaceView . Surface only valid after the surfaceCreated and before surfaceDestroyed of the SurfaceHolder in the SurafceView.That is to say, the operation of configuring the display area can only be performed after receiving the surfaceCreated callback.\nTo configure the display area, you need to use the eglCreateWindowSurface method. The first two parameters are the objects we obtained in the above two steps. The third parameter is a Surface related parameter, which can be Surface , SurfaceHolder . In addition, you can also use the fourth parameter to pass some configuration information about Surface . After the function call is successful, we obtain a EGLSurface object.\nConnect them together #So far, the EGLDisplay object and the EGLSurface object are still independent. The latter only obtains some configuration information from the former, and has no other connection. In order to associate the two together, we need to borrow the EGLContext object. Similarly, creating a EGLContext object requires passing the eglCreateContext function. The first two parameters are the EGLDisplay and EGLConfig obtained in the previous step. , the special one is the third parameter. The third parameter is EGLContext , usually EGL_NO_CONTEXT is passed, which means creating an independent EGLContext object. Another situation is that when two rendering environments want to share resources, EGL_NO_CONTEXT should be passed normally when creating the first rendering environment. When creating the second rendering environment, you need to pass the EGLContext object is passed in, then the second rendering environment can use the textures, shaders, shader programs, and buffer class objects created in the first rendering environment, which are shared by the two rendering environments. got some data. At this point, three important objects have appeared, but they are not connected to each other yet, so the eglMakeCurrent function is needed to complete this work. This function will bind the EGLContext object to the current thread and also bind the EGLContext object to EGLSurface . After the binding is completed, the three major The objects are connected and the OpenGL ES environment is ready.\nBefore entering the world of OpenGL ES, we finally review the previous EGL world in code.\nval display = EGL14.eglGetDisplay(EGL14.EGL_DEFAULT_DISPLAY) if (EGL14.EGL_NO_DISPLAY == display) { log() return } val versions = IntArray(2) var flag = EGL14.eglInitialize(display, versions, 0, versions, 1) if (!flag) { log() return } Log.i(TAG, \u0026#34;EGL version:major = ${versions[0]}, minor = ${versions[1]}\u0026#34;) val attr = intArrayOf( EGL14.EGL_RED_SIZE, 8, EGL14.EGL_GREEN_SIZE, 8, EGL14.EGL_BLUE_SIZE, 8, EGL14.EGL_NONE ) val configs=Array\u0026lt;EGLConfig?\u0026gt;(1,{null}) val numConfig=IntArray(1) flag = EGL14.eglChooseConfig(display, attr, 0, configs, 0, 1, numConfig, 0) if (!flag) { log() return } val config=configs.first() val eglSurface=EGL14.eglCreateWindowSurface(display,config,surface, intArrayOf(EGL14.EGL_NONE),0) if (EGL14.EGL_NO_SURFACE == eglSurface) { log() return } val context=EGL14.eglCreateContext(display,config,EGL14.EGL_NO_CONTEXT, intArrayOf(EGL14.EGL_NONE),0) if (EGL14.EGL_NO_CONTEXT == context) { log() return } flag = EGL14.eglMakeCurrent(display, eglSurface, eglSurface, context) if (!flag) { log() return } Enter the world of OpenGL ES #After a long preparation, we finally prepared the rendering environment and can use the OpenGL ES API normally. Typically, this is followed by creating shaders and shader programs. Of course, different rendering scenarios usually call different APIs. In this article, we want to dye the window red, so there is no need to create these things. We only need to call two APIs. glClearColor Set the clear screen color.glClear Set the clear screen bit.\nOf course, these two functions alone are not enough. We haven\u0026rsquo;t set the drawing area yet. Yes, you can specify the drawing area separately for each drawing. For example, for the first drawing, we draw in the upper left corner, and for the second drawing, we can draw in the lower right corner. You only need to specify the drawing area before drawing. The drawing area The specification will be valid until the next re-specification, and the function used is glViewport . The first two parameters of the function specify the starting position, and the last two parameters are the distance from the starting position.\nWith the help of these three functions, OpenGL ES will dye our dark black frame red. Let\u0026rsquo;s take a look at the code\n//We want to render the entire area, so the start point is the top left corner and the end point is the width and height of the view GLES20.glViewport(0,0,width,height) //Colour range is 0-1 GLES20.glClearColor(1f,0f,0f,1f) GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT) Display #We have dyed the window red in the previous section, but after running the application, we will find that the display is still black. That is because we forgot the final screen operation. Because after entering the OpenGL ES world, the logical thing to do is to call the OpenGL ES API. However, the fact is to always remember that the OpenGL ES API is only responsible for drawing. For display-related issues, you have to contact EGL. After OpenGL ES drawing is completed, you need to use eglSwapBuffers to complete the screen operation.\nSummary #This article is the first in the OpenGL ES series. It focuses on my general understanding of EGL and OpenGL ES. The expression may not be so rigorous. It is intended to help readers build a channel to enter this field and understand some main concepts. Basic impression, we will go into each link one by one in the later stage, hoping to have the effect of attracting new ideas.\nAfter reading this article, readers should have a simple impression of the process of developing OpenGL ES applications: EGL environment preparation, shaders, shader programs, rendering, screen loading, and cleanup. Of course, this article only focuses on the preparation of the EGL environment.\nRegarding EGL environment preparation, we have three objects, which are the display, display area, and display context, corresponding to EGLDisplay , EGLSurface , and EGLContext . Environment preparation mainly starts from EGLDisplay , obtains and configures these three objects, and finally uses eglMakeCurrent to associate them. Of course, after using the OpenGL ES API to complete rendering, remember to use `eglSwapBuffers`` to complete the screen operation.\nPlease refer to here for the source code.\n","date":"9 May 2023","permalink":"/en/post/learning%20opengles%20on%20the%20android-fill%20the%20window.html","section":"Posts","summary":"We know that the screen displays content by emitting RGB lamp beads one by one, and the brightness of the lamp beads is determined by a memory area. By writing data to this memory area, we can observe the data display effect on the screen. This is a complex and flexible job.","title":"Android OpenGLES learning-draw a color"},{"content":"","date":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/en/","section":"Deep thinking","summary":"","title":"Deep thinking"},{"content":"","date":null,"permalink":"/en/tags/opengles/","section":"Tags","summary":"","title":"OpenGLES"},{"content":"","date":null,"permalink":"/en/categories/opengles/","section":"Categories","summary":"","title":"OpenGLES"},{"content":"","date":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/en/tags/study/","section":"Tags","summary":"","title":"study"},{"content":"","date":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/en/tags/c++/","section":"Tags","summary":"","title":"C++"},{"content":"","date":null,"permalink":"/en/categories/c++/","section":"Categories","summary":"","title":"C++"},{"content":" Template have always had a pivotal role as an important feature of C++, and are a great tool for writing highly abstract code.\nWhat is template #Template are real-life examples: fix the parts that are all the same, leave the parts that change empty, and combine the two parts to form something valid when you use it. Application forms and Word templates are examples of this, as are templates in C++, but more explicitly in C++, where the variable part is a surrogate type, called a generic parameter.\nLet\u0026rsquo;s look at an example to see how templates evolved. If we need to calculate the result of adding two objects, how do we write the code? Before we write the code, we have a couple of issues that we need to discuss clearly: The first thing we need to determine is that the two objects are of what type, after all, C++ is a strongly typed programming language, variables, functions, and classes are explicitly specified as to what the type is, and the compilation of an unspecified type will not pass. Let\u0026rsquo;s assume for a moment that the two types are integers. Once we have determined the type, we need to determine how the two objects need to be added together. Based on our assumption that they are integers, we know that we can just call the operator +. Finally, we need to determine what the result type of the addition of the two objects will be, and the result of the addition of an integer type will also be an integer type. To summarize, the code for this example might look something like this\nint sum(int left,int right){ return left + right; } This example is simple, so simple that it doesn\u0026rsquo;t even need to be written as a separate function. What if the data we need to calculate is not two numbers, but the sum of an array? Based on the previous analysis and assumptions, we can also quickly implement the corresponding code\nint sum(const int data[], const std::size_t length) { int result{}; for (int i = 0; i \u0026lt; length;++i) { result += *(data + i); } return result; } Again, very simple. Unfortunately, this function is not very general, it can only compute integer sums, if we need to compute a sum with a decimal point, it doesn\u0026rsquo;t work because the first argument type doesn\u0026rsquo;t match, even though we know that almost all of sum\u0026rsquo;s code can be reused, except for the int in the first line, which needs to be replaced with double. But it can\u0026rsquo;t! We can only make a copy and change the int places to double.\ndouble sum(const double data[], const std::size_t length) { double result{}; for (int i = 0; i \u0026lt; length;++i) { result += *(data + i); } return result; } This is where you see the problem, this process, we have only changed the type information. The problem continues to grow, we may need to ask for an array sum of float again, the same array sum of double above won\u0026rsquo;t match, because float, double are two types. It is because the data types are different that many times we need to provide similar code for different data, which is painful in the case of bloated data types, and when making changes to the algorithm we need to make sure that all the data types are modified and tested one by one, which definitely increases the workload and amplifies the error rate. But the actual valid code is to specify the type, if the type is not clear, the compiler can not determine whether the code is legal, not sure things the compiler has to report an error, so in accordance with the ordinary thinking, this problem is not solved.\nBut in fact, very often, these similar codes are simply different data types, and dealing with this repetitive work should be left to the computer, i.e. the compiler. So we need a technique that allows the compiler to not care what the specific type is in the first place, but to replace it with a special type that can be replaced with any type, complete the specific algorithm with this special type, and provide the type information to the algorithm based on the actual needs at the time of use to allow the compiler to generate a specific algorithm that satisfies the provided type, which is a template. This is ideologically common with templates in life. The algorithm is the fixed part, the data type is the variable part, and the two together make legal C++ code. That is, using templates, we can write just one algorithm, and with the help of the compiler generate algorithms of all types, and the only difference between these algorithms is the type.\nOf course the template is not enough, the above only solves the problem of the type, did not solve the problem of algorithm implementation. How so, e.g. we have a requirement to sort the data first and then find the maximum value. This is valid for numeric (int, float, double, etc.) types, and can be done using comparison operators (\u0026lt;, \u0026gt;), but what if we want to make this algorithm work for custom types? Writing the comparison operator directly in the template implementation won\u0026rsquo;t work for custom types because they don\u0026rsquo;t have a corresponding comparison function. The solution is simple: the custom type implements the corresponding comparison operator. Problems such as these will often be encountered in the template, because we do not know anything about the type of information, but to ensure that almost all types can work properly, which will have to use a variety of techniques to qualify or detect the type, which is actually the essence of the template problem. So the template problem is not just a type problem, or a combination of other C++ problems, and requires a more complete understanding of C++ features in order to write useful and efficient code. In C++, templates are usually divided into function templates and template classes, so let\u0026rsquo;s start with the simpler function templates.\nFunction template #A function template is a function that differs from a regular function in that at least one of its argument list is of indeterminate type. Continue with our example above:\ntemplate \u0026lt;typename T\u0026gt; T sum(const T data[], const std::size_t length) { T result{}; for (int i = 0; i \u0026lt; length;++i) { result += *(data + i); } return result; } int main() { int intData[] = { 1, 1, 2, 2 }; float floatData[] = { 1, 1, 2, 2 }; double doubleData[] = { 1, 1, 2, 2 }; auto len = sizeof(intData)/sizeof(intData[0]); std::cout \u0026lt;\u0026lt; \u0026#34;intSum = \u0026#34; \u0026lt;\u0026lt; sum\u0026lt;int\u0026gt;(intData,len) \u0026lt;\u0026lt; \u0026#34;, floatSum = \u0026#34; \u0026lt;\u0026lt; sum\u0026lt;float\u0026gt;(floatData,len) \u0026lt;\u0026lt;\u0026#34;, doubleSum = \u0026#34; \u0026lt;\u0026lt;sum\u0026lt;double\u0026gt;(doubleData,len)\u0026lt;\u0026lt;std::endl; return 0; } // output // intSum = 6, floatSum = 6, doubleSum = 6 Here, we\u0026rsquo;ve just written a function that works for int, float, and double. If there are other types that implement the default initialization and operator += you can also use this function to sum without changing any existing code, that\u0026rsquo;s the beauty of templates. Before moving on to something new, let\u0026rsquo;s recognize the difference between a function template and a regular function:\nFunction templates require a template header, template\u0026lt;typename T\u0026gt;. It serves to tell the compiler that none of the following functions where T is encountered are of a specific type, and that it needs to be determined again when the function is called. In the function declaration, the type position is replaced by T, which means that T is a placeholder type that can be used as a normal type. This is useful when writing boilerplate code. Looking again at the use of functions, that is, statements like sum\u0026lt;xxx\u0026gt;(xxxData,len), where xxx represents the data type, which is the actual type of T in the function template. This simply tells the compiler to replace the type T in the function template with the type xxx, a process that has an official name, instantiation, which is another thing that is different from normal functions\u0026hellip;. Using function templates is a two-step process.\nDefine the template. This step does not have a specific type and requires the use of a generic parameter to placeholder the type, i.e., wherever an actual type occurs, use the generic parameter to placeholder it and use this generic parameter to implement the complete algorithm. In this step the compiler, since it does not know the exact type, will not disable some type operations, but only check if the identifier exists, if the syntax is legal etc. Instantiation. The process of instantiation happens only where the developer calls the function template, the code of the function template that is not instantiated does not appear in the most executable file. The compiler will replace the generic parameter with the actual parameter for each place where instantiation occurs, and check whether the actual type supports all the operations in the algorithm, if not, the compilation fails, and the developer needs to implement the relevant operations or modify the function template. As in the above example, if we instantiate a custom type, we will find that the compilation fails because the custom type does not define the operator += (unless that operator is already defined), and this process occurs in the instantiation. The solution is simple: add the operator += to the custom type. Type derivation #In the above example, we found that in the process of instantiation, we have to pass both the type parameter and the data parameter to the function template, and the type parameter is often one-to-one with the type of the data, which is a redundant syntax for modern C++ is unacceptable, so modern C++ compilers all support type derivation. Type derivation allows the developer to omit the type parameter and derive the type parameter directly from the data type, so the above example instantiation can be written in the form of sum(xxxData,len), and the compiler will be able to derive the type of xxx to be int, float, and double respectively. Of course, type derivation is not foolproof, let\u0026rsquo;s look at the following example\ntemplate \u0026lt;typename T\u0026gt; T max(T a, T b) { return a \u0026gt; b ? a : b; } int main() { int a = 1; int b = 2; std::cout \u0026lt;\u0026lt; \u0026#34;max(\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;,\u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34;) = \u0026#34; \u0026lt;\u0026lt;max(a,b) \u0026lt;\u0026lt; std::endl; return 0; } // output // max(1,2) = 2 This example is intuitive, and the result is certainly unsurprising. Now we\u0026rsquo;re going to morph: we change the type of the variable b to float and realize that the compilation won\u0026rsquo;t pass. The hint is that we have a data type mismatch, because a is int and b is float, so the deduction is max\u0026lt;int,float\u0026gt;(), whereas in reality we have only one type parameter. So since the problem is clear, the solution seems simple enough, wouldn\u0026rsquo;t it be enough to add another parameter to max? Let\u0026rsquo;s take a look.\ntemplate \u0026lt;typename A,typename B\u0026gt; A max(A a, B b) { return a \u0026gt; b ? a : b; } int main() { int a = 1; float b = 2; std::cout \u0026lt;\u0026lt; \u0026#34;max(\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;,\u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34;) = \u0026#34; \u0026lt;\u0026lt;max(a,b) \u0026lt;\u0026lt; std::endl; return 0; } // output // max(1,2) = 2 After this change, it compiles and runs without errors, so the problem seems to be solved, right? No, it\u0026rsquo;s not. Let\u0026rsquo;s replace float b = 2; with float b = 2.5;.\nint main() { int a = 1; float b = 2.5; std::cout \u0026lt;\u0026lt; \u0026#34;max(\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;,\u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34;) = \u0026#34; \u0026lt;\u0026lt;max(a,b) \u0026lt;\u0026lt; std::endl; return 0; } // output // max(1,2.5) = 2 Run the program again, and you\u0026rsquo;ll see that the output is wrong. This is because in the function template, we defined the return value as A, and at instantiation time A was derived to be of type int, so in fact the return value of max became of type int, and the maximum value, B, was forcibly converted from a float to an int, and the data precision was lost. So is there a solution? There is, and there is more than one! According to the above analysis, the root of the problem is that the data has been forcibly converted, and the solution is of course to prevent it from happening, that is, to keep the two data types consistent, so how to ensure it? Block the compiler\u0026rsquo;s type derivation, manually fill in the type parameter.\nint main() { int a = 1; float b = 2.5; std::cout \u0026lt;\u0026lt; \u0026#34;max(\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;,\u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34;) = \u0026#34; \u0026lt;\u0026lt;max\u0026lt;float\u0026gt;(a,b) \u0026lt;\u0026lt; std::endl; return 0; } // outout // max(1,2.5) = 2.5 As you can see in this example, we only filled in one type parameter, because type B is automatically deduced to float. Yes, type derivation can be partially disabled! Another solution is to let the compiler calculate the type entirely. How to calculate it, C++11 provides auto and decltype. auto calculates the type of a variable, and decltype calculates the type of an expression, as follows:\nauto a=1; // a is derived as type int auto b=1.5; // b is derived as type double decltype(a+b) //the result is type double That is, you can set the return value to auto and let the compiler decide the return type\ntemplate \u0026lt;typename A,typename B\u0026gt; auto max(A a, B b) { return a \u0026gt; b ? a : b; } int main() { int a = 1; float b = 2.5; std::cout \u0026lt;\u0026lt; \u0026#34;max(\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;,\u0026#34;\u0026lt;\u0026lt;b\u0026lt;\u0026lt;\u0026#34;) = \u0026#34; \u0026lt;\u0026lt;max\u0026lt;float\u0026gt;(a,b) \u0026lt;\u0026lt; std::endl; return 0; } // output // max(1,2.5) = 2.5 If the compiler only supported C++11, it would be a bit tricky to not only front auto, but also use decltype after the function header to compute the return type, a feature known as tailed return derivation.\ntemplate \u0026lt;typename A,typename B\u0026gt; auto max(A a, B b)-\u0026gt;decltype(a + b) { return a \u0026gt; b ? a : b; } Here decltype is written inside the Let\u0026rsquo;s put the function templates aside for now, and let\u0026rsquo;s take a look at what the class template look like.\nClass template #Like function templates, class templates contain at least one generic parameter that is scoped to the entire class, meaning that member variables and member functions can be defined using this generic parameter.\ntemplate \u0026lt;typename T\u0026gt; class Result { T data; int code; std::string reason; public: Result(T data, int code = 0, std::string reason = \u0026#34;success\u0026#34;) :data{ data }, code{ code }, reason{ reason } { } friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const Result result) { os \u0026lt;\u0026lt; \u0026#34;Result(data = \u0026#34; \u0026lt;\u0026lt; result.data \u0026lt;\u0026lt;\u0026#34;, code = \u0026#34; \u0026lt;\u0026lt; result.code \u0026lt;\u0026lt;\u0026#34;, reason = \u0026#34; \u0026lt;\u0026lt; result.reason \u0026lt;\u0026lt;\u0026#34;)\u0026#34; \u0026lt;\u0026lt; std::endl; return os; } }; int main() { Result\u0026lt;int\u0026gt; result{ 9527 }; std::cout \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; return 0; } // output // Result(data = 9527, code = 0, reason = success) As you can see, the class template is similar to a regular class in that it has everything that a regular class has - member functions, member variables, constructors, etc. It\u0026rsquo;s still worth mentioning the generic parameter T. The above example is a common data class in the SDK, used to indicate whether an operation was successful or not and to return the result of the operation if necessary. For returning normal data types, this class is sufficient, but if one of our interfaces does not have a return value, and traditionally returns a void type, a problem arises. The actual type of data is void, but we can\u0026rsquo;t find any value to initialize it. Further, when returning void, we don\u0026rsquo;t need the data member variable at all. To solve problems like this one, templates provide specializations.\nSpecialization and partial specialization #Specialization is the reimplementation of a class template or function template with a specific type instead of a generic parameter, which depends on the original template. As in the above example, we already have the original template class Result\u0026lt;T\u0026gt;, in order to solve the case where void cannot be used, we need to redefine a Result for the void type, i.e., Result\u0026lt;void\u0026gt;, then Result\u0026lt;void\u0026gt; is known as a kind of specialization of Result\u0026lt;T\u0026gt; and the original Result\u0026lt;T\u0026gt; is called the original template class. There can be many such specializations, and a type is a specialization which perfectly combines the advantages of both generality and specificity. When instantiation is done, if the instantiated type and the specialization type are the same, the instantiation will be done using that class (function) of the specialization, as in the following example\n// Result definition remains unchanged, new specialization version added template \u0026lt;\u0026gt; class Result\u0026lt;void\u0026gt;{ int code; std::string reason; public: Result(int code = 0, std::string reason = \u0026#34;success\u0026#34;): code{ code }, reason{ reason }{} friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const Result result) { os \u0026lt;\u0026lt; \u0026#34;Result(\u0026#34;\u0026lt;\u0026lt;\u0026#34;code = \u0026#34; \u0026lt;\u0026lt; result.code \u0026lt;\u0026lt; \u0026#34;, reason = \u0026#34; \u0026lt;\u0026lt; result.reason \u0026lt;\u0026lt; \u0026#34;)\u0026#34; \u0026lt;\u0026lt; std::endl; return os; } }; int main() { Result\u0026lt;void\u0026gt; voidResult; Result\u0026lt;int\u0026gt; intResult{9527}; std::cout \u0026lt;\u0026lt; \u0026#34;void = \u0026#34;\u0026lt;\u0026lt; voidResult\u0026lt;\u0026lt;std::endl\u0026lt;\u0026lt;\u0026#34;int = \u0026#34; \u0026lt;\u0026lt; intResult \u0026lt;\u0026lt; std::endl; return 0; } // output // void = Result(code = 0, reason = success) // int = Result(data = 9527, code = 0, reason = success) As you can see, when instantiated to the int type, the original template class is used. And when instantiated as a void type, the specialization version is used. In addition to specialization, there is also preferential specialization. A partial specialization is much like a specialization in that it is a narrower qualification of the type to make it apply to a certain class of types, such as const, pointers, references, etc. Or partial specialization for classes with multiple generic parameters. Specialization and partial specialization are complementary to template special types and solve some problems with template implementation. Very often if the generic template is not well implemented, you can consider using specialization. Of course, the more versions of specialization, the higher the maintenance cost of the template, it is time to consider whether there is a design flaw.\nType qualification #The power of C++ templates is not only in the manipulation of types, but sometimes in order to prevent our classes from being abused, we need to qualify these abilities, such as disallowing the instantiation of certain specific types. In the example above, suppose we specify that Result must return actual data, what would be the best way to prohibit void instantiation? It\u0026rsquo;s easy to think that we would first need a way to determine whether the type at instantiation is of a particular type, and then we would need to tell the compiler to fail to compile if the instantiated type is a forbidden type. All of this is supported by the standard library type_traits. It provides a number of tools to help us recognize type parameters such as numbers, strings, pointers, etc. It also provides a number of other tools to assist these type parameter tools with more complex functions. In this case, we want the instantiation type not to be void, and after looking up type_traits, we find that there is a class is_void, which has a value constant that is true if the type parameter is void, and false otherwise. Of course it\u0026rsquo;s not enough to have a determination method, we also need a way for the compiler to report an error if the types don\u0026rsquo;t match, and as it happens, we have enable_if_t. It has two type parameters, the first is a boolean expression and the second is a type parameter. The type parameter is defined when the expression is true, otherwise the compilation fails. So in order to accomplish the function of disabling void instantiation, we need to use two tools, is_void to determine whether the type parameter is void or not, and enable_if_t to accomplish the conversion from boolean expression to type parameter. To summarize, let\u0026rsquo;s take a look at the implementation:\ntemplate \u0026lt;typename T\u0026gt; class Result { std::enable_if_t\u0026lt;!std::is_void\u0026lt;T\u0026gt;::value,T\u0026gt; data; int code; std::string reason; public: Result(std::enable_if_t\u0026lt; !std::is_void\u0026lt;T\u0026gt;::value,T\u0026gt; data, int code = 0, std::string reason = \u0026#34;success\u0026#34;) :data{ data }, code{ code }, reason{ reason } { } friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const Result\u0026lt; std::enable_if_t\u0026lt; !std::is_void\u0026lt;T\u0026gt;::value, T\u0026gt;\u0026gt; result) { os \u0026lt;\u0026lt; \u0026#34;Result(data = \u0026#34; \u0026lt;\u0026lt; result.data \u0026lt;\u0026lt;\u0026#34;, code = \u0026#34; \u0026lt;\u0026lt; result.code \u0026lt;\u0026lt;\u0026#34;, reason = \u0026#34; \u0026lt;\u0026lt; result.reason \u0026lt;\u0026lt;\u0026#34;)\u0026#34; \u0026lt;\u0026lt; std::endl; return os; } }; In the example, lines 3 and 8 both use type qualification, when in fact we only need to qualify T in the constructor. When instantiating Result with void, it will not compile.\nOther issues #There are two aspects of C++ templates that need to be addressed, one is the template-related issues and the other is working with other features. For example, C++11 introduced right-valued references, but right-valued references passed through parameters can cause references to collapse, losing their right-valued nature and behaving like normal reference types. This is fine for normal functions, but what if it\u0026rsquo;s a template function? C++ also provides the perfect forwarding solution. Perfect forwarding means that a right-valued reference stays a right-valued reference, and a left-valued reference stays a left-valued reference. It needs to be used in conjunction with universal references. Universal references are very similar to right-valued references, except that the universal reference type is indeterminate and can only be determined at compile time. Look at the following example\ntemplate \u0026lt;typename T\u0026gt; void test(T\u0026amp;\u0026amp; p) { std::cout \u0026lt;\u0026lt; \u0026#34;p = \u0026#34; \u0026lt;\u0026lt; std::forward\u0026lt;T\u0026gt;(p) \u0026lt;\u0026lt; std::endl; } int main() { int a = 1; test(a); test(std::move(a)); return 0; } // output // p = 1 // p = 1 T\u0026amp;\u0026amp; is a universal reference because it is of indeterminate type, and then the arguments are forwarded through std::forward\u0026lt;\u0026gt;. As you can see in lines 8 and 9, we successfully pass the left and right values to test and also successfully get the expected result without having to write a separate function for the right value to handle it. This feature of templates greatly simplifies function design and is a lifesaver for API design. In addition, function templates have the problem of overloading. Generally speaking, the priority of ordinary functions will be higher than the priority of function templates, function templates between the more special will be preferred to match and so on. These problems with the depth of understanding of the template, will slowly appear, but in the early stages of learning there is no need to spend too much effort to understand these features, everything to the main practical.\nSummary #Templates are a big topic in C++, combining the type system, the standard library, classes, and a host of other big topics. So writing perfect template code requires a complete understanding of these topics. Secondly, because the template type control is more relaxed, but also need to developers on the scope of application of the template has a global control, what is prohibited, what types need to be specialization of the treatment, should be considered in place, a little inattention will hide a difficult to detect the bugs. In short, it is a word, the template is always learning, often used often new, need to learn in practice, but also in the learning of things in practice, I wish you every time there are new gains!\nReference # type_traints ","date":"31 October 2022","permalink":"/en/post/Modern%20C++%20study%20guide-template.html","section":"Posts","summary":"Template have always had a pivotal role as an important feature of C++, and are a great tool for writing highly abstract code.\nWhat is template #Template are real-life examples: fix the parts that are all the same, leave the parts that change empty, and combine the two parts to form something valid when you use it.","title":"Modern C++ study guide-template"},{"content":"","date":null,"permalink":"/en/tags/study-guide/","section":"Tags","summary":"","title":"Study guide"},{"content":" In [the previous chapter](https://www.yuque.com/docs/share/adb5b1e4-f3c6-46fd-ba4b-4dabce9b4f2a?# Modern C++ Study Guide - The Type System) we explored the type system of C++ and proposed a low-to-high and again high-to-low study idea. This article is a study guide from high to low, and hopefully provides a new perspective.\nWhat is standard library #Programming languages are generally divided into two parts, one is the syntax part, such as the type system in the previous chapter, and the other part is the predefined toolset accomplished with this syntax, such as the subject of this article - the standard library. The standard library is a bunch of code that we can use directly when we write code, as if we had written it in advance. Not only that, the standard library is also cross-platform, or industrial-grade tested, so the standard library has the characteristics of reliability and security. The C++ standard library includes many aspects, including classes vector, string, objects std::cin, std::cout, and functions move, copy, etc., so they are generally categorized according to their functions.\nContainer Arithmetic Smart pointer Thread Other Of course, these are not all, the standard library is constantly expanding and improving, the purpose of learning the standard library should also be to learn their use scenarios, rather than in-depth usage. For example, there are many container classes with similar functionality, and there are different options for different business scenarios. Through their understanding, we are more likely to write efficient, concise code.\nContainer #A container class is a class that helps manage a set of data, and depending on how it is implemented, it is divided into ordered lists, unordered lists, and maps. Ordered in an ordered list means that the data set is stored in a contiguous area of memory, and can be directly located to the original data by the index at the time of insertion. Because the data is stored sequentially, if you need to delete or add data in the middle of the process, the data on the right side of the operation position will need to be moved, and the operation will be more expensive. It can also be seen that their advantages are sequential insertion and tail modification, as well as direct lookup, which is represented by array and vector. array is the encapsulation of the original array, and solves the problem of passing arrays as pointers, but the disadvantage is that its size is fixed, and it is suitable for use in cases where the amount of data is known. vector is an enhancement of array that not only does all the operations of array, but also has a variable size, so in most cases, vector is the ideal choice. ! The elements of the unordered list are stored separately, with each other using pointers to find neighboring elements, because pointers can be easily modified to point to the finger, so the modification of neighboring elements becomes very fast. By the same token, finding neighboring elements can only be done by pointer jumps, find a value need to start looking from a pointer, a jump a piece of data, until the target is found or no data until. So the advantage of unordered lists is to delete and insert new data quickly, not suitable for lookup, which is represented by list, forward_list. Obviously, ordered and unordered lists are complementary, and we should determine which container to choose based on the operation of the data in the actual project.\nA map, on the other hand, combines the advantages of both ordered and unordered lists, allowing for fast insertion and deletion as well as fast lookups. To fulfill various usage scenarios, C++ provides map, multimap, unordered_map, unordered_multimap. You can tell the difference between them by their names. To visualize it, I\u0026rsquo;ve made a direct table\nSorted or not Whether the same value is supported or not speed unordered_map ❌ ❌ ❤️❤️❤️❤️ map ✅ ❌ ❤️❤️ multimap ✅ ✅ ❤️ unordered_multimap ✅ ✅ ❤️❤️❤️ A map stores two values, which are implemented differently for different types. Since map is required to be sorted, it is usually implemented as a kind of balanced binary tree, with the keys being the basis for its sorting. An unordered_map does not need to be ordered, so its implementation is usually a hash table, i.e., it determines the index location and then the storage location based on the hash function. In summary, the container class provides an interface to manipulate multiple data of the same type, and the developer can realize the addition, deletion, modification and checking of the data inside the container by calling the container class methods. In most cases, vector is a reliable choice, it provides a full-featured data manipulation interface, supports dynamic length, indexed queries, and is simple and efficient. If frequent insertion or deletion operations are required, you can also consider list or forward_list. map keeps data organized, unorderer_map is a better choice if you need more speed than sorting, and multi can be used if the same value occurs more than once. Container classes are also a good resource for learning about data structures. C++\u0026rsquo;s container classes provide almost all forms of data structures, and the more familiar you are with data structures, the better container class you can choose.\nArithmetic #The reason why the algorithms are placed after the container classes is that the algorithms are mostly enhancements to the container class operations, and the algorithms are defined in the algorithm file header. These algorithms are short and concise, which can greatly increase code readability and properly handle many easily forgotten boundary issues. Functionality can be divided into add, delete, change and check several operations, you can actually have the need to check the documentation, you can refer to here\nSmart pointer #A long time ago, I wasn\u0026rsquo;t very nice about smart pointers. Because when I first started learning C++ I knew that you can\u0026rsquo;t use pointers alone, you have to encapsulate them in a class and use the class constructor and destructor to manage the pointers, also known as RAII. At first I thought that was enough, until I came across the following situation\npublic: Ptr():p{ new int } {} ~Ptr() { delete p; } int\u0026amp; get() { return *p; } void set(const int value) { *p = value; } private: int* p; }; void use(Ptr p) { //Passed in is a copy of the constructed p\u0026#39;, after the function returns p\u0026#39; is destroyed, the two pointers point to the address is reclaimed, outside the p pointer becomes a wild pointer. } int main() { Ptr p; p.set(1); use(p); //p is passed by value, and the copy constructor of Ptr is called, constructing a new object p\u0026#39;, whose pointer points to the same place as p\u0026#39;s pointer std::cout \u0026lt;\u0026lt; p.get() \u0026lt;\u0026lt; std::endl; //p has been destroyed, access to p\u0026#39;s address is illegal return 0; } When use is called, the variable p is copied, and there is a situation where two pointers point to a single memory address at the same time. After the use function is executed, its argument p is reclaimed. That is, the destructor of Ptr is called, which means that the addresses pointed to by the two pointers are reclaimed. So the call to get on line 24 to read the reclaimed address is illegal and the program crashes. This is probably one of the more common problems encountered by novices, of course, to solve this problem is also very simple, you can not use smart pointers, you only need to change the parameter of the function use to a reference type, because the reference is just an alias, it will not generate new pointers, which is one of the reasons why I highly recommend references as the preferred parameter type in the type system chapter. For this example, the data is not large, directly rewrite the copy constructor, reclaim a piece of memory is also an idea. This example uses Ptr in only one place, the actual project Ptr often need to be used many times, we can not guarantee that we will not forget to use the reference type of the situation, in this case re-apply for memory is not applicable, so this time you need to smart pointers to help. Now think about another scenario, where we have to expose our pointers for external use for certain operations, and as the nesting and call chaining of operations increases, many times we forget or are unsure of when to call delete to free the memory. This is also a scenario where smart pointers are used. Both of these scenarios require shared pointers, which correspond to shared_ptr in smart pointers. As the name shared_ptr suggests, it helps developers to accomplish the problem of sharing pointers, and perfectly solves the problems of releasing them early, not knowing when to release them, and who is responsible for releasing them. It corresponds to a one-to-many relationship, where an actual memory can be shared by more than one shared_ptr. Another scenario is that we want a pointer to belong to only one object at a time from the beginning, and an external party wants to use it either through the object method that owns the pointer or by transferring ownership of the pointer to itself, which corresponds to unique_ptr in smart pointers. The correspondence of unique_ptr is one-to-one; at any given moment, only one manager can have the pointer, and it is the only one responsible for releasing it. If you want to transfer this correspondence, you can only do so with the std::move operation, but after this operation, the pointer to the original object is invalidated, and it is no longer responsible for managing it; all the tasks are transferred to the new object. This feature is particularly suitable for resource-sensitive applications.\nThread #Besides memory, threads are another important topic in development. The difficulty with threads is that not only do you have to manage the thread objects, but you also have to manage the resources managed by the thread objects and ensure data synchronization between threads. Of course the standard library has done a good enough job, we need to understand is the problem of the use of the scene. The thread library consists of a thread object thread, a condition object condition_variable, and a lock object mutex. Using thread makes it easy to write programs as multithreaded in three steps:\nvoid plus(int a,int b){ //Step 1: Define the function to be run in the thread std::cout\u0026lt;\u0026lt;\u0026#34;running at sub thread\u0026#34;\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;\u0026#34;a + b = \u0026#34;\u0026lt;\u0026lt;a+b\u0026lt;\u0026lt;std::endl; } int main(){ std::thread thread{plus,1,1}; //Step 2:define the std::thread object, taking the function as a parameter std::cout\u0026lt;\u0026lt;\u0026#34;continue running at main thread\u0026#34;\u0026lt;\u0026lt;std::endl; thread.join(); //Step 3:call the join function or detach function of the thread object std::cout\u0026lt;\u0026lt;\u0026#34;sub thread finished!\u0026#34;\u0026lt;\u0026lt;std::endl; } //输出 //\tcontinue running at main thread //\trunning at sub thread // a + b = 2 // sub thread finished! The difficulty is inter-thread communication, that is, solving two problems\nthread 1 updates the value of variable v thread 2 immediately reads the correct value of variable v, i.e., the latest value updated by thread 1. In order to coordinate these two processes, there is a lock object mutex and a condition object condition_variable. The lock object mutex ensures that variables are changed in the correct order. The condition object condition_variable ensures that the changes are heard by other threads.\nint a,b; bool ready = false; std::mutex mux; std::condition_variable con; void plus() { std::cout \u0026lt;\u0026lt; \u0026#34;running at sub thread\u0026#34; \u0026lt;\u0026lt; std::endl; //Because we want to read the latest value of ready, we need to use a lock to ensure the validity of the read result std::unique_lock\u0026lt;std::mutex\u0026gt; guard{ mux }; if (!ready) { //The data wasn\u0026#39;t ready, take a break! con.wait(guard); } //Here you can read the variables a,b correctly std::cout \u0026lt;\u0026lt; \u0026#34;a + b =\u0026#34; \u0026lt;\u0026lt; a + b \u0026lt;\u0026lt; std::endl; } int main() { std::thread thread{ plus}; std::cout \u0026lt;\u0026lt; \u0026#34;continue running at main thread\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;input a = \u0026#34;; std::cin \u0026gt;\u0026gt; a; std::cout \u0026lt;\u0026lt; \u0026#34;input b = \u0026#34;; std::cin \u0026gt;\u0026gt; b; { //Once the data is ready, it\u0026#39;s time to notify the child threads to do their work, using curly braces because you want the lock to be released even if the guard is destroyed, and there is no guarantee that the lock will be reacquired inside PLUS. std::unique_lock\u0026lt;std::mutex\u0026gt; guard{ mux }; //Updated data ready = true; //notification con.notify_all(); } thread.join(); std::cout \u0026lt;\u0026lt; \u0026#34;sub thread finished!\u0026#34; \u0026lt;\u0026lt; std::endl; } Another issue to be aware of with multithreading is deadlocks. Deadlocks are based on the premise that there are two locks\nthread 1 has lock a and wants lock b thread 2 has lock b, and wants lock a. Then, add a premise: at a certain time, only one thread can have a certain lock, it is not difficult to conclude that: thread a, b unless one of the locks abandoned, otherwise both threads will not get the locks needed to wait for a deadlock. At the same time, the idea of solving the deadlock is also out: since a got a, a got b, and the lock at the same time can only be obtained by a thread, then all the threads according to the order of the first to get a, and then to get b, there will not be a lock is occupied problem. Another way to think about this is to start with abandonment. Since neither of them can get it, the next task can\u0026rsquo;t be done, so you might as well just abandon the ones you\u0026rsquo;ve already got, so consider using timed_mutex.\nOther #There are also many commonly used libraries, such as string string, time chrono, as well as functional, exception exception, which are commonly used when defining function variables, and more can be found in cplusplus for reference.\nSummary #In general, the Standard Library provides a platform to show the power of the C++ language: it helps developers to accomplish their development tasks better and faster, and at the same time, it inspires developers to realize better abstractions and practices. For example, I have learned to define function parameters in a more standardized way, better encapsulation, and other good ideas from the library. Learning the standard library not only better grasp of the language itself, but also mastered a more comprehensive way to analyze the problem, problem-solving approach, it is worth spending a period of time to learn. Container class is almost all projects will use, but also better to master, mainly from the data structure against the learning; smart pointers is a good helper to deal with the pointer problem; thread-related libraries is more difficult to master, the key is to understand the use of scenarios and extreme cases of boundary problems. Many times boundary issues may not be so intuitive. For example, the thread request to obtain the lock is divided into the following cases: the lock is idle, the lock is occupied by other threads, and the lock is occupied by itself. Different boundaries for different locks, the expected results are different, only in the case of clear scenarios, in order to better clarify the relationship between locks, so as to solve the problem. The best way to learn is to actively use it in practice. For me, when I encounter a new problem, I usually check the standard library first to see if there is a corresponding library, and if there is, it\u0026rsquo;s a good time to learn it. You can start with an overview of the definition of the library and the problem it solves, then analyze the classes, functions, objects, etc. it provides, then convert your understanding into code in the project, and finally test and revise your ideas in the real world to complete the learning of the library.\n","date":"20 July 2022","permalink":"/en/post/Modern%20C++%20Study%20Guide%20-%20Standard%20Library.html","section":"Posts","summary":"In [the previous chapter](https://www.yuque.com/docs/share/adb5b1e4-f3c6-46fd-ba4b-4dabce9b4f2a?# Modern C++ Study Guide - The Type System) we explored the type system of C++ and proposed a low-to-high and again high-to-low study idea. This article is a study guide from high to low, and hopefully provides a new perspective.\nWhat is standard library #Programming languages are generally divided into two parts, one is the syntax part, such as the type system in the previous chapter, and the other part is the predefined toolset accomplished with this syntax, such as the subject of this article - the standard library.","title":"Modern C++ Study Guide - Standard Library"},{"content":" In the previous post, we provided a directional guide, but what and how to learn was not developed in detail. This article will build on the previous article and focus on how to learn C++\u0026rsquo;s type system.\nBefore the start #Before we get into the type system, there is one thing we should agree on - use the modern syntax of C++ whenever possible. It is well known that many syntaxes in C++ are legal for compatibility reasons. But as new versions are released, some syntax may not be recommended or needs to be avoided. So this post also uses the recommended form of syntax (based on C++11 or above) whenever possible, which is what the title Modern C++ means.\nThere are two benefits to using modern syntax. One, modern syntax can compile faster and more robust code. Compilers evolve as languages evolve, and modern syntaxes can help compilers do better optimization to some extent. Second, modern syntaxes are often more concise, intuitive, and uniform, which helps increase readability and maintainability. With that clear, let\u0026rsquo;s get our foot in the door of modern C++.\nType system #A program is a computational tool that produces computational results based on inputs, and predefined computational methods. When the program is run, all three need to be represented in memory as appropriate values for the program to work properly, and the set of tools responsible for interpreting this is the type system. Numbers, strings, keyboard and mouse events, etc. are all data and actually exist in memory in the same form, but are treated differently when viewed through our human eyes. Numbers can be added, subtracted, multiplied, divided, and other arithmetic operations, but arithmetic operations on strings are meaningless, and keyboard and mouse values are usually just read, not calculated. It is because of these differences that the first task of a programming language is the need to define a type system that tells the computer what to do with the data in memory. In order to make programming languages as simple as possible, programming languages generally implement the type system in two steps, one for the compiler and the other for the types. The compiler part is responsible for interpreting the developer\u0026rsquo;s code into a suitable form so that it can be efficiently and accurately represented in memory. The type part defines the types that the compiler can handle, so that the developer can find the right data to accomplish the representation of inputs and outputs and the description of computational methods. The two complement and fulfill each other. The importance of types as an important representation of the type system in a programming language cannot be overstated. If you think of writing a program as building blocks, then the blocks of the program are the type system. The type system is the smallest unit that the developer can manipulate, it limits the rules of operation, but provides unlimited possibilities. c++ has a type system that is more flexible than the building blocks.\nType #:::info Types are the smallest unit of a programming language, and any sentence of code is a form of memory usage. ::: Talking about types in C++ also brings us to its three types of representation - normal types, pointers, and references. They are three different forms of memory usage and interpretation, and are the most basic forms of C++. Unlike most programming languages, C++ does not privilege built-in types, and all types can have a consistent syntax (via operator overloading) if the developer wants them to, so the following examples of types are suitable for all types. Common types are types without modifiers, such as int, long, double, etc. They are passed by value, i.e., assignments and function passes make a copy of the value. They are passed by value, which means that assignments and function passes make a copy of the value, and operations on the copied value do not affect the old value any further.\nint a=1; //old value, exists at address 1 int b=a; // new value, exists at address 2 b=2; //change new value, change address 2 // At this point a is still 1 and b becomes 2 ! So what if we need to modify the old value, there are two ways to do this, one is a pointer and the other is a reference. Pointers are the magic inside C/C++, everything is a pointer. A pointer has two aspects, on the one hand it refers to a block of memory and on the other hand it can refer to the operations that are allowed to be performed on that block of memory. The value of a pointer is a block of memory address, and by manipulating a pointer, you manipulate the block of address it points to.\nint a=1; //old value, exists at address 1 int* b=\u0026amp;a; //\u0026amp; stands for fetch address, read from right to left, fetch address of a - address 1, exist address 2 *b=2; //* is dereferencing, meaning take out the value that exists at address 2(b) and change the value at that address (address 1) to 2 // At this point a, *b becomes 2 ! References are an improved version of pointers. References avoid invalid references, but they cannot be reset and lack a certain degree of flexibility over pointers.\nint a=1; //old value, exists at address 1 int\u0026amp; b=a; //\u0026amp; appears at the position of the variable declaration, which means that the variable is a reference variable, and reference variables must be initialized at the time of declaration b=2; // you can manipulate a reference variable like a normal variable, and at the same time, operations on it will be reflected on the original object // At this point a, b becomes 2 Variable definitions #A type is just a syntactic definition, and to actually use that definition, we need to define variables in terms of types, i.e. variable definitions. C++ variable definitions are of the following form:\ntype name[{initial_value}] The key here is type. type is a combination of type and qualifier. Look at the following example:\nint a; // Ordinary integer int* b; //The type is a combination of int and *, forming an integer pointer const int* c; //reading from right to left, * is a pointer and const int is a constant integer, making up the type of pointer to a constant integer int *const d; // also read from right to left, const is constant, followed by a pointer, indicating that this pointer is a constant pointer to the leftmost int, which consists of constant pointers to integers int\u0026amp; e=a; //The type is a combination of int and \u0026amp;, forming an integer reference constexpr int f=a+e; //constexpr means that this variable needs to be evaluated at compile time and is no longer mutable. Above, basically all the forms of variable definition, the type determines the basic attributes of the variable, and the qualifier limits the scope of the variable\u0026rsquo;s use. Defining a variable follows this same procedure, first determining what type of variable we need, and secondly further determining if we need to add a qualifier to that variable, which many times is required. The following steps can be followed to determine what kind of qualifier to add:\nis a large object, consider declaring the variable as a reference type. Usually reference types are a better choice than pointer types. Large objects may need to be reset, consider declaring them as pointers. Just want a constant, add constexpr. To read only this variable, add const. Variable initialization #Variable definitions are often accompanied by initialization, which is important for local variables because the initial value of a local variable is uncertain, and using a variable without effectively initializing it can lead to uncontrollable problems. So strictly speaking, the preceding variable definition is not entirely correct. C++11 introduced a new, unified way of initializing variables, where the variable name is followed by curly braces that enclose the initialized value. This approach can be used for any variable and is called uniform initialization, as in:\nint a{9527}; // common type string b={\u0026#34;abc\u0026#34;}; //another way to write, equivalent but not recommended Student c{\u0026#34;ZhangSan\u0026#34;, \u0026#34;20220226\u0026#34;,18}; //in curly brackets are constructor parameters Of course, in addition to defining a variable by its type name, you can also combine definition and initialization into the cleanest form below:\nauto a={1}; // deduce to integer auto b=string{\u0026#34;abc\u0026#34;}; auto c=Student{\u0026#34;Zhang San\u0026#34;, \u0026#34;20220226\u0026#34;,18} Here auto means to let the compiler determine the type itself. The above is written in a way that makes full use of C++\u0026rsquo;s type derivation, which is the recommended form for many modern languages. Note, however, that = cannot be omitted when type derivation is used. Once we have initialized variables, we can use them for a variety of computational tasks.C++ implements a lot of built-in computational support for developers. C++ implements a lot of built-in computational support for the developer, such as addition, subtraction, multiplication and division of numbers, indexing of arrays, pointer manipulation, etc. There are also branching if, switch, looping while, for, etc. statements which provide us with more flexibility.\nFunctions #Variables are the smallest unit in a programming language, and as the complexity of a business increases, there are times when intermediate computations distract from the logic of the business and add complexity. In order to better organize the code, the type system adds functions to solve this problem. A function is also a type, a composite type. Its type consists of a combination of argument list and return value, which means that two functions, if they have the same argument list and return value, are equivalent from the compiler\u0026rsquo;s point of view. Of course, they are not enough, otherwise how can there be two parameter list and return value of the same function. A complete function also needs to have a function body and function name. So a function is usually of the following form:\n// Regular function form [constexpr] return value Function name (argument list) [noexcept]{ function body (math.) } // Return value in postfixed form auto function name (argument list) -\u0026gt; return value When a function does not have a body, we usually call it a function declaration. Adding a function body is a function definition.\nvoid f(int); //function declaration void fun(int value){ // function definition as represented by curly braces function body } This is the basic framework of a function, so let\u0026rsquo;s take a look at each of the parts that make it up. First of all, the simplest function name, it is actually a function of this type of a variable, the value of this variable represents a block of code starting from a certain location in the memory address. As I said earlier, the reason why there can be two parameter lists and return values are the same function, but the compiler can identify, the main credit in the function name, so the function name is also the same as the name of the variable, is a kind of identifier. Then if the reverse, the same function name, but the parameter list or return value is different, this situation has a term - function overloading. Based on the understanding that functions are composite types, it is considered overloading if only one of them is different. In addition, in C++11, there is another kind of function without a name, called a lambda expression. lambda expressions are a kind of function value that is similar to a direct quantity, like 13, \u0026lsquo;c\u0026rsquo;, which is a kind of function that is not defined ahead of time, but is defined and used directly at the caller. The parameter list is an upgrade from the previous type definitions. All of what was said earlier about variable definitions applies to it, all three forms of variable definitions, multiple variables, variable initialization, etc. However, they all have new terms. Variables with a list of parameters are called formal parameters and initialization is called default parameters. Similarly formal parameters need to be initialized when they are actually used, but the initialization comes from the caller. Formal parameters without defaults need to be supplied at the time of calling and those with defaults can be omitted.\nint plus(int a,int b=1){ //b is a default parameter return a+b; } int main(void){ int c=plus(1); // no value for b is provided, so b is initialized to 1, resulting in 2 int d=plus(2,2); //a,b are initialized to 2, resulting in 4 //int f=plus(1,2,3); //plus has only two formal parameters, i.e. two variables, so it can\u0026#39;t hold three values, so it compiles incorrectly. return 0; } Like the argument list, the return value is a variable that is returned to the caller via a return statement, so in terms of memory manipulation, it is an assignment operation.\nstd::string msg(){ std::string input; std::cin\u0026gt;\u0026gt;input; return input. } int main(void){ auto a=msg(); std::string b=msg();//the input returned by msg is copied into b return 0; } Unfortunately, C++ only supports a single return value, that is, a function call can only return a maximum of one value, if there is more than one value can only be returned in the form of a formal parameter, this way for the function call is not very friendly, so C++ proposed a new solution.\nClasses #As the complexity of the business increases again, the number of formal parameters of a function may increase, or it may be necessary to return multiple values that are then passed between several different functions. This can lead to easily misplaced data and increased learning costs for the user. To solve these problems, engineers came up with object-oriented - multiple data packaging techniques. Expressed at the language level, it is using classes to package together a set of operations and the data needed to complete this set of operations. Data as a class attribute, operation as a class method, the user through the method to operate the internal data, data no longer need to pass the user, management. This is undoubtedly for the developer is greatly simplified operation. We call this object-oriented programming, and the way to pass data between functions is called procedure-oriented programming. The underlying logic of these two ways is in fact the same, the transfer of parameters and function calls are not less, but the difference between object-oriented is that these cumbersome, error-prone work to the compiler to do, the developer only needs to do a good job in accordance with the rules of the design of the object-oriented work on it, the rest to the compiler. At this point, we have moved up one level in our type system. Classes are not only aggregates of multiple types, they are also aggregates of multiple functions, a higher level of abstraction than functions. You can see the following code comparison between procedural and object-oriented programming\nstruct Computer{ bool booted; friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os,const Computer \u0026amp; c){ os\u0026lt;\u0026lt;\u0026#34;Computing\u0026#34;; return os. } }; void boot(Computer\u0026amp; c){ c.booted=true; std::cout\u0026lt;\u0026lt;\u0026#34;Booting...\u0026#34; ; } void compute(const Computer\u0026amp; c){ if(c.booted){ std::cout\u0026lt;\u0026lt;\u0026#34;Compute with\u0026#34;\u0026lt;\u0026lt;c; } } void shutdown(Computer\u0026amp; c){ c.booted=false; std::cout\u0026lt;\u0026lt;\u0026#34;Shutdown...\u0026#34; ; } int main(void){ auto c=Computer(); boot(c). compute(c). shutdown(c). return 0; } The most significant manifestation of procedural orientation is that the developer needs to pass data between functions and maintain the data state, which in the above example is c.\nstruct Computer{ bool booted; friend std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os,const Computer \u0026amp; c){ os\u0026lt;\u0026lt;\u0026#34;Computing\u0026#34;; return os. } void boot(){ booted=true; std::cout\u0026lt;\u0026lt;\u0026#34;Booting...\u0026#34; ; } void compute(){ if(booted){ std::cout\u0026lt;\u0026lt;\u0026#34;Compute with\u0026#34;\u0026lt;\u0026lt;this; } } void shutdown(){ booted=false; std::cout\u0026lt;\u0026lt;\u0026#34;Shutdown...\u0026#34; ; } }; int main(void){ auto c=Computer(); c.boot(); c.compute(); c.shutdown(); return 0; } The most significant change that can be seen in object-oriented code is that methods have fewer parameters, but the data defined by the class can be accessed directly inside the method. Another change occurs on the calling side. Instead of passing data to the method, the caller calls the method with data. This is the essence of object-orientation - it is data-centric. Of course, the encapsulation function of the class is only a small part of the class function, we will cover more class knowledge later. As a beginner, we understand this step will be able to read most of the code.\nSummary #The type system is the basic component of a language, which supports the high-level functions of the whole system, and many high-level features are evolved on the basis of the type system. Therefore, learning the type system of a language is a process from low to high, and from high to low. Starting from the most basic types, we learn how to construct high-level types from the low-level types, and then stand on the height of high-level types, and examine how the high-level types are constructed from the low-level types. This up and down, high and low basically makes most of the features of the language clear. Low-level types are more oriented towards making the compiler work better, and high-level types are more oriented towards making the developer work better. C++ provides various levels of support from common types, functions, and classes, which gives the developer more freedom of choice, and of course makes it more difficult for the developer to learn. But developers don\u0026rsquo;t always need all the choices, so I think the right learning should be guided by the size of the project. Some projects, which don\u0026rsquo;t use object orientation at all, can focus on building function sets that work well. And there are projects where object orientation is a good choice, and time needs to be spent on classes. Going back to the building blocks example at the beginning, the choice of building blocks depends entirely on what we want to model, and if we don\u0026rsquo;t have the right ones, we can create our own. That\u0026rsquo;s the beauty of C++.\n","date":"26 June 2022","permalink":"/en/post/modern-c++-study-guide-type-system.html","section":"Posts","summary":"In the previous post, we provided a directional guide, but what and how to learn was not developed in detail. This article will build on the previous article and focus on how to learn C++\u0026rsquo;s type system.\nBefore the start #Before we get into the type system, there is one thing we should agree on - use the modern syntax of C++ whenever possible.","title":"Modern C++ Study Guide - Type Systems"},{"content":"","date":null,"permalink":"/en/tags/study-guides/","section":"Tags","summary":"","title":"Study guides"},{"content":"C++ is a forty-year-old language that has gone through four major version upgrades (Birth, 98, 11, 17(20), 14 counts as a minor upgrade). Each upgrade was a trade-off between many problems and solutions. Understanding this history can better help us to clarify the development of the language. So next I will borrow its development history, talk about my understanding of it, and finally give a guide to what I think is a more reasonable learning route.\nC++0——be born #C++ was created to solve two main problems - performance and abstraction. Performance refers to the ability to have C-like underlying access and execution efficiency, while abstraction is meant to provide the ability to describe problems and ways of thinking at the language level. This is the foundation of C++ and the reason why C++ has endured. The solution that Bjarne Stroustrup came up with for both of these goals was to leverage existing C techniques and tools, and then provide classes to solve the abstraction problem. Based on this premise, we can see that classes are the first hurdle on the road to learning C++. C++ considers classes to be a form of abstract thinking, and the relevant features of classes are provided in the service of abstraction. So classes in C++ offer more capabilities than other object-oriented classes, and so have more complexity. In order to describe this complexity, it is necessary to mention two features of C++, static type safety, and resource management. Static type safety helps developers to define custom classes that are more reasonable and legal, e.g., through operator overloading, custom classes can be written with the same concise code as basic types. Runtime errors caused by implicit type conversions can be avoided through constructors, and one can stop one\u0026rsquo;s classes from being abused by explicitly blocking certain operations. All autonomy is up to the developer. So if we are users of the library, we don\u0026rsquo;t have to worry about these details, we just have to write the code as we would in a normal language, and if it doesn\u0026rsquo;t make sense, the compiler will just tell us, and we don\u0026rsquo;t have to worry that these problems will be hidden at some point in the program\u0026rsquo;s runtime.\nResource management, on the other hand, can help developers provide guidance and support for resource management. There are many kinds of resources, and most of the resources in a computer are limited, and must be borrowed and returned, and the borrowing and returning must be one-to-one correspondence, otherwise it is a memory leak. In the C era, resource management relied on the developer\u0026rsquo;s global control of resources, and no better support was provided at the language level. In order to better support resource management, C++ proposes constructors and destructors, which can correspond to the acquisition and recovery of resources. However, in many cases, resources are not only for your own use, but also need to be made available for external use. In order to support this kind of resource transfer, C++ provides move and copy operations. To summarize, C++ classes provide many features, but not all of them are needed by developers. The main question a developer needs to consider when defining a class is what support is provided for the class, and then choosing the appropriate syntactic features to implement among those provided. Constructors and destructors provide good one-to-one operations, moves and copies provide how resources can be shared among objects, and operator overloading allows classes to be used more concisely and elegantly.\nC++98——standardized #The biggest upgrades to C++98 are templates and exceptions, and they are paired with a good standard library. The place of templates in C++ cannot be overemphasized. It is another abstraction mechanism. Classes in C++ address the abstraction of similar concepts, focusing more on the similarity between concepts, whereas templates address generic problems. While templates solve the abstraction of generic problems, focusing more on the generality of concepts. Together, they form the two cornerstones of abstraction in C++. We\u0026rsquo;ve\nalready talked about classes, so let\u0026rsquo;s focus on templates. Thanks to C++\u0026rsquo;s strong static type safety, templates are easy to write, and they can be used to write ordinary functions in any way you like, just by replacing specific types with generic ones. But, on the other hand, templates can do much more. A template can support multiple parameters, multiple arguments, qualified parameters, and be type-safe. What\u0026rsquo;s even more impressive is that it can also specify values. Using types and values together wisely basically solves most problems.\nSpeaking of exceptions. They don\u0026rsquo;t have much appeal to the average developer. This is because the main problem that exceptions solve is how to tell the caller that an error has occurred, what the error is, and transfer the ability to execute to the caller\u0026rsquo;s side. And most of the time we develop business code, we know what happened, how to solve, most of the time is not much need for exceptions. Of course, it\u0026rsquo;s not that exceptions are useless; they are exceptionally important to the library developer. The library developer needs to be able to tell the caller that an error has occurred and that the operation is not going to work when the exception occurs. Often, however, the library developer doesn\u0026rsquo;t know what the caller should do with the error, whether to ignore it or clean up the mess. The exception mechanism provides both exception throwing and exception catching to support library developers and users.\nFor newbies, you may not like the standard library much and tend to write your own. This is not a good idea. Standard libraries are industry-tested code that will work in most situations, whereas writing your own code by hand gives you a better sense of accomplishment, but is more likely to carry bugs.Early standard libraries offered limited functionality, with only string, input/output streams, bitwise arithmetic, the three main containers, and a few small algorithms. However, these are sufficient for our daily use, especially now that the standard library has become more and more complete, and most programming scenarios can be accomplished with the right tools, it is possible to give up writing specific code by hand.\nC++98 was more about standardization, templates were a standard, and the standard library was a standard. Since then, the three pillars of C++ have been completed: classes, templates, and standard libraries. Each of them brings unlimited possibilities and vitality to C++.\nC++11——new language #The changes in C++11 are revolutionary, but retaining incredible compatibility is not easy. We won\u0026rsquo;t go into specific features and details here, just a general overview of the general direction.\nThe first intuitive change is in the type system, which C++11 standardizes and unifies as much as possible.\nC++11 has standardized and unified the type system as much as possible. It has standardized the form of initialization of objects by agreeing to initialize them; The form of type declarations is simplified by auto; Null pointers are standardized through nullptr; Static type-safe enumerations are provided through enum class; simplified type writing through aliases; And much, much more. Improvements to the type system mean that developers can write cleaner, more standardized, and safer code, but the challenges to compilers are huge, so for a long time, C++11 was not well supported, and also hindered the development of C++. In addition to the type system, another big improvement is the provision of threading support. the standard library of C++11 provides threads, conditional objects, locks, and other threading-related tools, which is revolutionary for library developers. Cross-platform threading support is provided with almost no loss of performance, which greatly improves the stability and performance of the library and saves a lot of time in platform testing, which has to be top notch.\nAnother important upgrade is resource management. The standard library provides unique_ptr, shared_ptr to assist in resource management. Right-valued references and move semantics have also been introduced for better performance. Right references and move semantics may sound high end, but they actually solve the problem of avoiding the repetitive creation and destruction of large objects in favor of less expensive moves. The underlying idea is twofold: for direct quantities, right references are provided to increase their lifetime, allowing them to be passed through parameters like normal variables. And for variables, move semantics are provided to transfer resources managed by objects that no longer need to be used to another pair of imagines. Also added move constructs, copy constructs way to optimize the return value of the function. It can be said to drain every inch of memory from the computer.\nC++11 is undoubtedly a landmark update to C++, and it carries on the role of cleaning up the historical legacy while leading the way for the rest of C++\u0026rsquo;s development. Improvements to the type system undoubtedly make up for some of the shortcomings inherited from C at the very beginning. It also took into account the development of modern computers and introduced threading support. It also took memory management to the next level, introducing smart pointers, move semantics, and right-valued references. It basically throws off the historical constraints, but still does not forget its mission, and still runs towards better static type support, more autonomy, more efficient resource management, and more restrained feature support.\nC++17，20——newborn #C++17 and C++20 are supposed to complement each other, and the vast majority of features are already supported and improved. However, due to compiler limitations, there are fewer features that I use. one of the more anticipated features of C++17 is the cross-platform filesystem support, which is certainly exciting and delightful for most application developers. Another feature I like is structured binding, which I use a lot in Python, but of course it\u0026rsquo;s supported by basically all modern languages now.\nAnd for C++20 it\u0026rsquo;s much less used, more of an example nature. I\u0026rsquo;m more concerned about modules and concurrency, but I won\u0026rsquo;t go into details since I don\u0026rsquo;t know much about them.\nWhat are the fundamentals of C++ #From the first few chapters it is easy to see that I have emphasized boasting about C++ classes, templates, standard library, and type system. These are the more important aspects of learning C++ in my opinion. But for beginners, I think The type system and the standard library are enough.\nThe type system is the smallest unit of a language. In C++, it includes type declarations, object initialization, function passing, and function return values. It\u0026rsquo;s a lie how many features you learn at the beginning of the learning process, but in reality you need to start with the smallest unit of the language. For example, when declaring a variable, what type of variable should it be, can it be a pointer, can it be a reference. When defining a function, how to determine the parameter list, what is the return value, how to make the function pass parameters efficiently, how to prevent and avoid useless parameter checking, what type of return value should be, and so on, these are in the actual project need to directly face the problem. So learning about the type system is the first and most important step in writing efficient and usable code. The more in-depth and comprehensive consideration of the issue, the greater the return.\nThe standard library, on the other hand, provides good algorithmic support and container support that can help us write more robust code. Learning about the standard library interfaces promotes awareness of the type system on the one hand, and on the other hand, it is a place to build up good habits.\nWith these two skills in place, I feel like I\u0026rsquo;ve been able to write great applications. But for library designers, writing great libraries also requires a deeper understanding of classes and templates. A well-defined class needs to have tight control over the object lifecycle, construction, transfer, and destruction. For operations that need to be supported, the class designer should provide the most convenient and efficient support possible, and for operations that are prohibited by the class, the class designer should explicitly prohibit them to prevent misuse or hidden bugs. so for the class, the focus needs to be on the construction of the resources, as well as the transfer and sharing of resources among multiple objects. Problems are likely to occur in the function passing and return value, especially the function of the layer call, efficiency and safety is a must consider, so this is back to the type system mentioned earlier, only a more in-depth understanding of it, in order to design a better class.\nTemplates are the other side of the class, it and the class concept is different, but the idea is similar. Templates are similar to generics in Java, but are more flexible and important, and are the same height as classes. Templates need to consider the question of what algorithms to provide, what objects can use this algorithm, how to avoid and prevent the misuse of the wrong object, in the process of use how to avoid run-time errors by using compilation errors as much as possible. So it is a further abstraction than a class, and has higher requirements for the developer than a class.\nC++ Learning Roadmap #From the previous section, you can see that my recommended learning path is the type system, to the standard library, to classes, and finally to templates. The other details of the language are not unimportant, but will be integrated into the learning process while learning the four main sections, there is no need to learn and understand separately, after all, the details are complex and scattered, will not increase the mastery of the language, but will disrupt the learning rhythm and distraction. The learning of the type system can in turn be carried out in the following steps\nVariable declarations (constants and compile-time constants) Initialization (uniform initialization, assignment) Function definitions, function parameter definitions, return values (use of references, pointers) Simple class definitions, not involving memory management, resource management Standard libraries can be performed in the following steps Smart pointers (shared_ptr, unique_ptr, etc.) Strings Container class objects (list,map, etc.). Standard input and output usage Threaded library usage Generic algorithms (sort, find, etc.) Classes can proceed as follows Class constructors, move constructors, copy constructors Class operator overloading Inheritance Virtual functions Multiple Inheritance Templating can be done in the following steps Template Functions Template classes Template recursion Template specialization Summary #C++ is full of details, beginners can easily dive into the details of the syntax without realizing it, and end up wasting a lot of time, not to mention, but also a serious blow to the motivation to learn. The main purpose of this article is to help beginners clear the main vein of this language, and provide me with a more scientific learning route, I hope to help beginners.\nC++ is a general-purpose language with a long history of development. It has a lot of historical baggage, so it has been restrained in introducing language features and how to introduce them. However, in order to better serve modern hardware and simplify the work of developers, new features have had to be introduced and old ones left behind. For this reason, the language exhibits some complexity and clutter. But its core direction is clear: to better address efficiency and abstraction. By grasping these two core aspects and combining them with this guide, you can get a good grasp of most of the language by starting with the hard ones and then moving on to the easy ones, and then adding a little generalization and summarization. For the features outside the guide, it\u0026rsquo;s not too late to learn them when you need them in a real project. After all, most of the time the features we use are only a small part of the language, so we should spend our energy on the most cost-effective parts.\n","date":"25 June 2022","permalink":"/en/post/Modern%20C++%20Study%20Guide-roadmap.html","section":"Posts","summary":"C++ is a forty-year-old language that has gone through four major version upgrades (Birth, 98, 11, 17(20), 14 counts as a minor upgrade). Each upgrade was a trade-off between many problems and solutions. Understanding this history can better help us to clarify the development of the language. So next I will borrow its development history, talk about my understanding of it, and finally give a guide to what I think is a more reasonable learning route.","title":"Modern C++ Study Guide-roadmap"},{"content":"Sometimes it is necessary to use libraries written in C/C++ for security, performance, and code sharing considerations during the development. Although with the support of modern tool chains, the difficulty of this work has been greatly reduced, after all, everything is difficult at the beginning, and beginners often still encounter many unpredictable problems. This article is a simple guide written based on this background. I hope it will be helpful to readers who have just started writing C/C++ libraries. At the same time, in order to reduce cognitive gaps as much as possible, this article will try to start with the simplest function and gradually add tool chains until the final function is achieved, truly knowing what is happening and why.\nTarget #The goal of this article is very simple, which is to call C/C++ functions in Android applications - receiving two integer values ​​and returning the value after adding the two. This function is tentatively named plus.\nBegin with the C++ source file #In order to start from where we are most familiar, we\u0026rsquo;ll start with the original C++ source files without the use of sophisticated tools.\nOpen any text editor you like, VS Code, Notpad++, Notepad, create a new text file and save it as math.cpp. Next, you can write code in this file.\nOur goal, as stated earlier, is to implement a plus function that takes two integer values and returns the sum of the two, so it might look like below\nint plus(int left,int right) { return left + right; } Out work is done, isn\u0026rsquo;t it simple.\nBut just having the source file is not enough, because this is just for humans, machines can\u0026rsquo;t read it. So we need the first tool - a compiler. A compiler helps us to convert what is human-readable into something that is machine-readable.\nThe compiler #The compiler is a complex project, but the two main functions are as follows\nto understand the content of the source file (human-readable) - to check for syntax errors in the source file to understand the content of the binary (machine-readable) - to generate binary machine code. Around these two main functions, the compiler needs to complete a lot of work, especially function 2. Based on this difficulty, compilers are divided into a variety of common compilers, such as VS for Windows platform, G++ for Linux platform, Apple\u0026rsquo;s Clang, and for Android, the situation is slightly different, the previous compilers are running on a specific system, compiled programs usually can only run on the corresponding system. The compiled program usually only runs on the corresponding system. Taking my current machine as an example, I\u0026rsquo;m writing C++ code on Deepin right now, but the goal is to have the code run on an Android phone, two different platforms. More pessimistically, so far, there is no compiler that will run on a phone. Does that mean we can\u0026rsquo;t run C++ code on a phone? Of course not, because there is cross-compilation.\nCross-compilation is the technique of generating code on one platform into executable objects on another. The biggest difference between cross-compilation and normal compilation is in linking. Because the general link directly to the system library to find the appropriate library files, while cross-compilation can not, because the current platform is not the final platform to run the code. So cross-compile also need to have the common libraries of the target platform. Of course, Google has prepared all these for us, called NDK.\nNDK #NDK full name is Native Development Kit, there are many tools, compilers, linkers, standard libraries, shared libraries. These are all essential parts of cross-compilation. In order to understand the convenience, we first take a look at its file structure. Take the version on my machine as an example - /home/Andy/Android/Sdk/ndk/21.4.7075529 (the default location on Windows is c:\\Users\\xxx\\AppData\\Local\\Android\\\\). Sdk\\). The NDK is stored in the Sdk directory, named ndk, and the version number is used as the root directory for that version, as in the example, the version of NDK I installed is 21.4.7075529. The example is also the value of the ANDROID_NDK environment variable. In other words, before determining the environment variable, we need to determine the version of the NDK to use, and the path value is taken to the version number directory.\nKnowing where it is stored, we next need to recognize two important directories\nbuild/cmake/, a folder that we\u0026rsquo;ll expand on later. toolchains/llvm/prebuild/linux-x86_64, the last linux-x86_64 has a different name depending on the platform, e.g. it starts with Windows on Windows platforms, but you can\u0026rsquo;t go wrong with it because it\u0026rsquo;s just one folder under the path and it\u0026rsquo;s preceded by the same one. There are compilers, linkers, libraries, headers and so on. For example, the compilers are in the bin directory in this path, and they all end in clang and clang++, like aarch64-linux-android21-clang++. aarch64 means that this compiler can generate binaries for use on arm64 architecture machines, the other equivalents are armv7a, x86_64, etc. Different platforms use matching compilers. It is the target platform that is referred to in cross-compilation.\nlinux means that we perform the compilation operation on a linux machine, which is the host platform in cross-compilation.\nandroid21 is obviously the target system version.\nclang++ means that it is a C++ compiler, and the corresponding C compiler is clang.\nAs you can see, for Android, different hosts, different instruction sets, different Android versions, all correspond to a compiler. After learning so much, it\u0026rsquo;s finally time to get excited about the human nature. Next, let\u0026rsquo;s compile the C++ file in front of us.\nCompile #Looking at the parameters via aarch64-linux-android21-clang++ --help, you\u0026rsquo;ll see that it has a lot of parameters and options, and now we just want to verify that our C++ source file doesn\u0026rsquo;t have any syntax errors, so we\u0026rsquo;ll just ignore all that complexity, and just a aarch64-linux-android21- clang++ -c math.cpp.\nAfter the command is executed, if all goes well, a math.o object file will be generated in the same directory as math.cpp, which means that our source code has no syntax errors and we can proceed to the next step of linking.\nBut before that, a quick interruption. Often our projects contain many source files, referencing some third-party libraries, and each time we compile them manually, linking is obviously inefficient and error-prone. Nowadays, when tools are mature, we should try to use mature tools and focus on our business logic, CMake is one such tool.\nCMake #CMake is a cross-platform project builder. How to understand it? When writing C++ code, sometimes you need to refer to file headers in other directories, but in the compilation stage, the compiler doesn\u0026rsquo;t know where to look for the headers, so you need a configuration to tell the compiler where to look for the headers. Furthermore, source code distributed in different directories needs to be packaged into different libraries according to certain needs. Or, if the project references third-party libraries, you need to tell the linker where to look for the libraries during the linking phase, and all of these are things that need to be configured.\nDifferent systems and different IDEs have different support for these configurations, such as Visual Studio on Windows, which needs to be configured in the project\u0026rsquo;s properties. When developers use the same tools, the problem is not so big. But once involved in the case of multi-platform, multi-IDE, collaborative development will spend a lot of time in the configuration of the CMake is to solve these problems came into being.\nCMake configuration information is written in a file called CMakeLists.txt. As I mentioned earlier, header file references, source code dependencies, library dependencies, etc., only need to be written once in CmakeLists.txt, and can be used seamlessly on all major IDEs on Windows, MacOS, and Linux platforms. For example, I created a CMake project on Visual Studio for Windows, configured the dependencies, and passed it to a coworker. When my colleague develops on MacOS, he can immediately finish compiling, packaging, testing, etc. without any modification. This is the power of CMake cross-platform - simple, efficient, flexible.\nManage project with CMake #Create a CMake project #We already have math.cpp and CMake above, so let\u0026rsquo;s combine them now.\nHow do we create a CMake project? There are three steps:\nCreate a folder In the example, let\u0026rsquo;s create a folder math.\nCreate a new CMakeLists.txt text file in the new folder. Note that the name of the file cannot be changed.\nConfigure the project information in the new CMakeLists.txt file. The simplest CMake project needs to include at least three infomation\nMinimum CMake version supported cmake_minimum_required(VERSION 3.18.1) Project name project(math) Product - The product could be executables or libraries. Since we are need a libraries on Android, so the product is a library. add_library(${PROJECT_NAME} SHARED math.cpp) After these three steps, the CMake project is built. Let\u0026rsquo;s try compiling the project with CMake in the next step.\nCompile the CMake project #Before executing the real compilation, CMake has a preparation phase, in which CMake collects the necessary information and then generates a project that meets the conditions before it can execute the compilation.\nWhat is the necessary information? CMake will collect some information by guessing in order to minimize the complexity.\nFor example, if we perform the generation operation on Windows, CMake will default to Windows as the target platform and generate the VS project by default, so compiling Windows libraries on Windows is almost zero configuration.\nCreate a new build directory in the math directory and switch the working directory to the build directory.\ncd build cmake .. After the command is executed, you will find the VS project in the build directory, and you can open it directly with VS and compile it without errors. Of course, the faster way is to compile directly with CMake.\nCompile\ncmake --build . Note that the preceding .. represents the parent directory, the math directory where the CMakeLists.txt file exists, and . represents the current directory, build. If both of these steps are executed successfully, we will be able to harvest a library file in the build directory, which may be called math.dll on Windows platforms and math.so on Linux platforms, but both are dynamic libraries, because that is what we configured in the CMakelists.txt file.\nFrom the above process, CMake\u0026rsquo;s workflow is not complicated. But we are using the default configuration, which means that the final generated library can only be used on the compiled platform. To use CMake to compile Android libraries, we need to manually tell CMake some configurations when generating the project, instead of letting CMake guess.\nCross-compilation of CMake #Where do the configuration parameters come from? #Although we do not know what is the minimum configuration to complete the cross-compilation, but we can guess.\nFirst of all, to complete the compilation of the source code, compiler and linker is indispensable, we also know that the Android platform has a special compiler and linker, so at least one configuration should be to tell CMake with which compiler and linker.\nSecondly, Android\u0026rsquo;s system version and architecture is also essential, after all, for Android development, this is very important for Android applications.\nCan you think of any other parameter, I can\u0026rsquo;t seem to think of any. However, the good news is that Google has done it for us, and that is to use CMAKE--TOOLCHAIIIN_FILE directly. This option is provided by CMake, just set the configuration file path to its value, CMake will find the target file through this path, and use the configuration inside the target file instead of its own guessing parameters. The configuration file is build/camke, one of the two important folders mentioned earlier, and our configuration file is android.toolchain.cmake under that folder.\nThe CMake of Google #android.toolchain.cmake plays the role of a wrapper that will work together to configure CMake using the parameters provided to it, and the default configuration. In fact, this file is a good source for learning about CMake, and you can learn a lot of CMake tricks. Now, let\u0026rsquo;s not learn CMake-related first, let\u0026rsquo;s see what parameters we have available. In the beginning of the file, Google will be configurable parameters are listed out\nANDROID_TOOLCHAIN ANDROID_ABI ANDROID_PLATFORM ANDROID_STL ANDROID_PIE ANDROID_CPP_FEATURES ANDROID_ALLOW_UNDEFINED_SYMBOLS ANDROID_ARM_MODE ANDROID_ARM_NEON ANDROID_DISABLE_FORMAT_STRING_CHECKS ANDROID_CCACHE These parameters are not actually CMake parameters; they are converted to real CMake parameters as the configuration file is executed. We can specify the values of these parameters to allow CMake to fulfill different build requirements. If you don\u0026rsquo;t specify any of them, the default values will be used, which may be different for different NDK versions.\nLet\u0026rsquo;s focus on the most critical ANDROID_ABI and ANDROID_PLATFORM. The first one refers to which CPU instruction set the currently built package is running on, the available values are arneabi-v7a, arn64-v8a, x86, x86_64, mips, mips64. The latter one refers to the Android version of the build package. Its value takes two forms, one is the direct android-[version] of the form [version] which is replaced with the specific system version when used, e.g., android-23, which means that the minimum supported system version is Android 23. The other form is the string latest. This value is as the word implies, use the latest.\nSo how do we know which parameter can take which values? There\u0026rsquo;s an easy way: first identify the parameter you want to see in the header of the file, then search globally and look at the set and if related statements to determine the parameter forms it supports.\nComplete cross-compilation using configuration files #With that out of the way, let\u0026rsquo;s go back to the original example. Now we have CMakelists.txt, we have math.cpp, and we have found the configuration file android.toolchin.cmake for Android. So how do you combine the three, which brings us to CMake\u0026rsquo;s parameter configuration.\nIn the previous section, we completed the configuration of the project file generation by directly using the following command\ncmake .. But it is actually possible to pass parameters, CMake\u0026rsquo;s parameters are all key-value pairs that start with -D and are separated by whitespace. And CMake\u0026rsquo;s default parameters all start with CMAKE, so most of the time the parameters are of the form -DCMAKE_XXXFor example, passing a toolchain file to CMake would look like this\ncmake -DCMAKE_TOOLCHAIN_FILE=/home/Andy/Android/Sdk/ndk/21.4.7075529/build/cmake/android.toolchain.cmake The point of this parameter is to tell CMake to use the file specified after = to configure CMake\u0026rsquo;s parameters\nHowever, to complete the cross-compilation, we are missing one more option - -G. This option is required for cross-compilation. Because cross-compiling CMake does not know what form of project to generate, this option is needed to specify the type of project to generate. One type of project is the traditional Make project, which is specified as follows.\ncmake -G \u0026#34;Unix Makefiles\u0026#34; As you can see, this form is based on the Unix Make project, which uses make as the build tool, so after specifying this form, you also need to specify the path to make for the project to be compiled successfully. The other Google-recommended way is Ninja, which is simpler because you don\u0026rsquo;t need to specify the path to Ninja separately, and it is installed in the same directory as CMake by default, so you can reduce the number of passing parameters. Ninja is also a build tool, but focuses on speed, so we\u0026rsquo;ll use Ninja this time. It\u0026rsquo;s specified like this\ncmake -GNinja Combining the above two parameters gives you the final compilation command\ncmake -GNinja -DCMAKE_TOOLCHAIN_FILE=/home/Andy/Android/Sdk/ndk/21.4.7075529/build/cmake/android.toolchain.cmake .. Generate a project and then compile it\ncmake --build . We\u0026rsquo;ve got a dynamic library that will eventually run on Android. The dynamic library compiled with my version of the NDK supports Android version 21, and the instruction set is armeabi-v7a. Of course, based on the previous description, we can pass the desired parameters as we did earlier with the toolchain file, e.g., to build the x86 library with the latest version of Android, you can write something like this\ncmake -GNinja -DCMAKE_TOOLCHAIN_FILE=/home/Andy/Android/Sdk/ndk/21.4.7075529/build/cmake/android.toolchain.cmake -DANDROID_PLATFORM=latest -DANDROID_ABI=x86 .. This gives us the idea that if some third-party libraries don\u0026rsquo;t provide a compilation guide, but are managed by CMake, we can just apply the above formula to compile the third-party libraries.\nJNI #With the help of CMake, we have got the libmath.so dynamic library, but this library still can\u0026rsquo;t be used directly by Android apps, because Android apps are developed in Java (Kotlin) language, and they are all JVM languages, the code is running on the JVM. To use the library, you also need to find a way to get the library loaded into the JVM and then you can access it. It happens that the JVM really does have this capability, it is JNI.\nJNI basic concepts #JNI can provide bi-directional access from Java to C/C++, that is, you can access C/C++ methods or data in Java code, and vice versa, the same support, which is the process of the JVM can not be ignored. So to understand JNI technology, we need to think in terms of JVM.\nJVM is like a goods distribution center, no matter where the goods need to come to this distribution center, and then through it to distribute the goods to the destination. The goods here can be Java methods or C/C++ functions. But unlike ordinary courier is that the goods here do not know where their destination is, you need to find the distribution center itself. Then find the basis from where it is, that is, how to ensure that the distribution center to find the results of the uniqueness of it, the simplest way is, of course, the goods themselves to identify their own, and to ensure its uniqueness.\nObviously this is a good problem for Java, which has layers of mechanisms to guarantee uniqueness.\nthe package name guarantees the uniqueness of the class name; the class name can guarantee the uniqueness of the class under the same package name; 3. the method name can guarantee the uniqueness under the same class; and method names can be used to guarantee uniqueness under the same class. 4; method overloading can be used to determine the uniqueness of the class by the type and number of parameters. For C/C++, there is no package name and class name, so can we determine the uniqueness with method name and method parameters? The answer is yes, as long as we use the package name and class name as a kind of qualification.\nThere are two ways to add qualifications, one is simple and crude, directly to the package name class name as part of the function name, so that the JVM does not have to look at other things, directly crude package name, class name, function name and parameters of these correspond to determine the corresponding method on the other end. This method is called static registration. In fact, it\u0026rsquo;s very similar to broadcasting in Android: static registration for broadcasting is just brute-force writing in the AndroidManifest file, so you don\u0026rsquo;t have to configure it in the code, and it takes effect as soon as it\u0026rsquo;s written. In contrast to static registration, there must be a dynamic registration method. Dynamic registration is writing code that tells the JVM what functions correspond to each other, rather than having it look them up when the function is called. Obviously the advantage of this approach is that the call is a little faster, after all, we only need to register once, you can in subsequent calls directly access to the counterpart, no longer need to find the operation. However, the same and Android broadcast dynamic registration, dynamic registration is much more cumbersome, and dynamic registration should also pay attention to grasp the timing of registration, otherwise it is easy to cause the call to fail. We continue to libmath.so as an example.\nUse local library on the Java #Accessing C/C++ functions on the Java side is simple, in three steps:\nJava calls System.loadLibrary() method to load the library.\nSystem.loadlibrary(\u0026#34;math.so\u0026#34;); It\u0026rsquo;s worth noting here that CMake generates a dynamic library called libmath.so, but here it\u0026rsquo;s just math.so, which means that you don\u0026rsquo;t need to pass the lib prefix. After this step, the JVM knows that there is a plus function.\nJava declares a native method that corresponds to a C++ function. Correspondence means that the parameter list and return value should be the same, but the method name can be different.\npublic native int nativePlus(int left,int right); Often, it is customary to prefix native methods with native.\nCall this native method directly where needed. Calling the method is the same as a normal Java method, passing matching parameters and receiving the return value with the matching type.\nCombining these steps into a single class looks like this\npackage hongui.me; import android.os.Bundle; import androidx.annotation.Nullable; import androidx.appcompat.app.AppCompatActivity; import hongui.me.databinding.ActivityMainBinding; public class MainActivity extends AppCompatActivity { static { System.loadLibrary(\u0026#34;me\u0026#34;); } ActivityMainBinding binding; private native int nativePlus(int left,int right); @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); binding = ActivityMainBinding.inflate(getLayoutInflater()); setContentView(binding.getRoot()); // Example of a call to a native method binding.sampleText.setText(\u0026#34;1 + 1 = \u0026#34;+nativePlus(1,1)); } } Introducing JNI on the C/C++ side #JNI is actually for C/C++ is a layer of adaptation layer, in this layer mainly do the work of function conversion, do not do the implementation of specific functions, so, in general, we will create a new source file, used to deal with the JNI layer of the problem, and the JNI layer of the most important problem is, of course, the method of registration problems mentioned earlier.\nStatic registration #The basic idea of static registration is to write a C/C++ function signature corresponding to an existing Java native method, specifically in four steps.\nStart by writing the exact same function signature as the Java native function int nativePlus(int left,int right) Add the package name and class name in front of the function name. Because package names are split in Java with . split, whereas in C/C++ dots are usually used as function calls, to avoid compilation errors, you need to replace . is replaced with _. hongui_me_MainActivity_nativePlus(int left,int right) Converting function parameters. As mentioned earlier all operations are JVM based, and in Java these are natural, but in C/C++ there is no JVM environment, and providing a JVM environment would have to be in the form of adding parameters. In order to do this, any JNI function has to add two parameters at the beginning of the parameter list. The smallest environment inside Java is a thread, so the first parameter is the thread environment object JNIEnv, which represents the caller\u0026rsquo;s thread environment when calling this function, and this object is the only way for C/C++ to access Java. The second is the calling object. Since you can\u0026rsquo;t call methods directly in Java, you need to call them through a class name or a class, the second argument represents that object or class, which is of type jobjet. Starting from the third parameter, the parameter list corresponds to the Java side, but only just, after all, there are some types that are not available in the C/C++ side, which is the type system in JNI, for our current example the int value in Java corresponds to the jint value in JNI, so the last two parameters are of type jint. This is a critical step, as failure to convert any of the parameters can cause the program to crash. hongui_me_MainActivity_nativePlus( JNIEnv* env, jobject /* this */, jint left, jint right) Add the necessary prefixes. This step can be easily overlooked because this part doesn\u0026rsquo;t come so naturally. First we have to add a prefix Java to the function name, which now looks like this Java_hongui_me_MainActivity_nativePlus. Secondly, you need to add JNIEXPORT and JNICALL at the end of the return value, here the return value is jint, so after adding these two macros it looks like this JNIEXPORT jint JNICALL. Finally, you have to add the extern \u0026quot;C\u0026quot; compatibility directive at the beginning. As to why this step is added, interested readers can go to the details, the simple summary is that this is the JNI specification. After these four steps, the final version of C/C++ function signature looks like this\n#include \u0026#34;math.h\u0026#34; extern \u0026#34;C\u0026#34; JNIEXPORT jint JNICALL Java_hongui_me_MainActivity_nativePlus( JNIEnv* env, jobject /* this */, jint left, jint right){ return plus(left,right); } Notice that here I changed the previous math.cpp to math.h and called the function in the JNI adaptation file (filename is native_jni.cpp). So now there are two source files, need to update CMakeList.txt a bit.\ncmake_minimum_required(VERSION 3.18。1) project(math) add_library(${PROJECT_NAME} SHARED native_jni.cpp) You can see that we only change the last line of the filename, because CMakeLists.txt is currently located in the directory is also include lookup directory, so do not need to give it a separate value, if you need to add other locations of the header file can be used to include_directories(dir) to add.\nNow use CMake to recompile and generate dynamic libraries, and this time Java will run directly without errors.\nDynamic registration #As mentioned earlier dynamic registration needs to pay attention to the timing of registration, so what is considered a good time? In the previous section of Java\u0026rsquo;s use of local libraries, we know that in order to use the library, you must first be loaded, loaded after the success of the JNI methods can be called. Then dynamic registration must occur after loading, before use. JNI is very humane to think of this, in the library after the completion of loading will immediately call jint JNI_OnLoad (JavaVM *vm, void *reserved) function, this method also provides a key JavaVM object, it is simply the best entry point to the dynamic registration of the It\u0026rsquo;s simply the best entry point for dynamic registration. Having determined the timing of the registration, let\u0026rsquo;s now do it in practice. Note: Dynamic registration and static registration are both ways of implementing JNI functions on the C/C++ side, and there is generally only one registration method for the same function. So, the next steps are parallel to static registration, not sequential.\nDynamic registration in six steps\nCreate a new native_jni.cpp file and add the implementation of the JNI_OnLoad() function. extern \u0026#34;C\u0026#34; JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM *vm, void *reserved) { return JNI_VERSION_1_6; } This is the standard form and implementation of this function, the previous string are the standard form of JNI function, the key point is the function name and parameters and return value. In order for this function to be called automatically after the library is loaded, the function name must be this, and the parameter form can not be changed, and the final return value to tell the JVM the current JNI version. In other words, these are templates, just copy.\nGet JNIEnv object As mentioned earlier, all JNI-related operations are done through the JNIEnv object, but now we only have a JavaVM object, so obviously the secret is in the JavaVM. The secret lies in the JavaVM. You can get the JNIEnv object through its GetEnv method.\nJNIEnv *env = nullptr; vm-\u0026gt;GetEnv(env, JNI_VERSION_1_6); Find the target class As I said earlier, both dynamic and static registration are most qualified by package and class names, just not in the same way. So for dynamic registration we still have to use the package name and class name, but this time in a different form. Static registration uses _ instead of . , this time we\u0026rsquo;re going to use / instead of . . So we end up with a class of the form hongui/me/MainActivity. This is a string form, so how do we convert it to a jclass type in JNI, which is where JNIEnv from step 2 comes in.\njclass cls=env-\u0026gt;FindClass(\u0026#34;hongui/me/MainActivity\u0026#34;); This cls object is a one-to-one correspondence with the MainActivity in Java. With the class object the next step is of course the methods.\nGenerate an array of JNI function objects. Because dynamic registration can register multiple methods of a class at the same time, the registration parameters are in the form of an array, and the type of the array is JNINativeMethod. The purpose of this type is to associate the native method on the Java side with the JNI method, how it is done, look at its structure\ntypedef struct { const char* name; const char* signature; void* fnPtr; } JNINativeMethod; name corresponds to the name of the native method on the Java side, so the value should be nativePlus. signature corresponds to the parameter list of the native method plus the signature of the function type. What is a signature? It is a type shorthand. There are eight basic types in Java, as well as methods, objects, classes. Arrays and so on, all of these things have a set of corresponding string forms, as if it were a hash table, where the keys are string representations of the types, and the values are the corresponding Java types. For example, jint is a true JNI type, its type signature is I, which is the initial capitalization of int.\nFunctions also have their own type signature (paramType)returnType Here both paramType and returnType need to be JNI type signatures, with no separator between types.\nIn summary, the type signature of nativePlus is (II)I. Two integer arguments return another integer.\nfnPtr is, as its name suggests, a function pointer, and the value is our real nativePlus implementation (which we haven\u0026rsquo;t implemented yet here, so let\u0026rsquo;s assume it\u0026rsquo;s jni_plus for now). To summarize, the final array of function objects should look like this\nJNINativeMethod methods[] = { {\u0026#34;nativePlus\u0026#34;,\u0026#34;(II)I\u0026#34;,reinterpret_cast\u0026lt;void *\u0026gt;(jni_plus)} }; Registration Now that you have the jclass object representing the class, and the JNINativeMethod array representing the methods, and the JNIEnv object, combine them to complete the registration\nenv-\u0026gt;RegisterNatives(cls,methods,sizeof(methods)/sizeof(methods[0])); The third parameter represents the number of methods. We use the sizeof operation to get the size of all the methods, and then we use sizeof to get the size of the first element to get the number of methods. Of course, it\u0026rsquo;s fine to just manually fill in 1 here.\nImplementing JNI Functions In step 4, we used a jni_plus to represent the native implementation of nativePlus, but this function hasn\u0026rsquo;t actually been created yet, so we need to define it in the source file. Now the name of the function can be whatever you want, it doesn\u0026rsquo;t have to be as long as the static registration, just keep the final function name the same as the one used in the registration. However, the prefix extern \u0026quot;C\u0026quot; should be added here, to avoid the compiler to do something special with the function name. The argument list is identical to the static registration. So, our final function implementation is as follows.\n#include \u0026#34;math.h\u0026#34; extern \u0026#34;C\u0026#34; jint jni_plus( JNIEnv* env, jobject /* this */, jint left, jint right){ return plus(left,right); } Well, the implementation of dynamic registration is now complete, and after CMake compiles it, you\u0026rsquo;ll see that the result is exactly the same as static registration. So it\u0026rsquo;s up to you to decide what you want and how you want to do it. When you need to call the native method a lot, I think dynamic registration is an advantage, but if you call it very rarely, you can just use static registration, and the lookup consumption is completely negligible.\nOne more thing #I mentioned earlier that CMake is a master at managing C/C++ projects, but for Android development, Gradle is the way to go. Google realizes this too, so the gradle plugin provides a silky smooth configuration for CMake and Gradle to work seamlessly together directly. Under the android build block, you can directly configure the path and version information of CMakeLists.txt.\nexternalNativeBuild { cmake { path file(\u0026#39;src/main/cpp/CMakeLists.txt\u0026#39;) version \u0026#39;3.20.5\u0026#39; } } This way, if you change your C/C++ code or Java code, you can just click run and gradle will compile the libraries and copy them to the final directory, so you don\u0026rsquo;t need to compile and copy the libraries manually anymore. Of course, if you are not satisfied with the default behavior, you can configure the default behavior via defaultConfig, which looks like this\nandroid { compileSdkVersion 29 defaultConfig { minSdkVersion 21 targetSdkVersion 29 testInstrumentationRunner \u0026#34;androidx.test.runner.AndroidJUnitRunner\u0026#34; consumerProguardFiles \u0026#39;consumer-rules.pro\u0026#39; externalNativeBuild { cmake { cppFlags += \u0026#34;-std=c++1z\u0026#34; arguments \u0026#39;-DANDROID_STL=c++_shared\u0026#39; abiFilters \u0026#39;armeabi-v7a\u0026#39;, \u0026#39;arm64-v8a\u0026#39; } } } } Here, cppFlags specifies C++-related arguments, and there\u0026rsquo;s a corresponding cFlags that specifies C-related arguments. arguments is to specify the compilation parameters of CMake, the last one is familiar with the library will eventually be compiled to generate a few architectural packages, we are here just to generate two.\nWith these configurations, Android Studio development NDK is exactly like the development of Java, there are intelligent prompts, can be compiled instantly, run instantly, enjoy the silky smooth.\nSumary #NDK development should actually be divided into two parts, C++ development and JNI development. C++ development is exactly the same as C++ development on PC, you can use standard libraries, you can refer to third-party libraries, with the expansion of the project scale, CMake was introduced to manage the project, which has obvious advantages for cross-platform projects, and can also be seamlessly integrated into Gradle. JNI development is more concerned about the correspondence between the C/C++ side and the Java side, each native method on the Java side should have a corresponding C/C++ function to correspond to it, JNI provides JNI provides both static registration and dynamic registration to accomplish this work, but the core is to use the package name, class name, function name, and parameter list to determine the uniqueness. Static registration reflects the package name and class name in the function name, while dynamic registration uses the class object, local method object, and JNIENV registration method to achieve uniqueness. NDK is the big boss behind, it provides compiler, linker and other tools to accomplish cross-compilation, and some system libraries, such as log, z, opengl and so on for us to use directly.\n","date":"6 March 2022","permalink":"/en/post/Introduction%20to%20Android%20NDK-basic%20concepts.html","section":"Posts","summary":"Sometimes it is necessary to use libraries written in C/C++ for security, performance, and code sharing considerations during the development. Although with the support of modern tool chains, the difficulty of this work has been greatly reduced, after all, everything is difficult at the beginning, and beginners often still encounter many unpredictable problems.","title":"Introduction to Android NDK-basic concepts"},{"content":"","date":null,"permalink":"/en/tags/jni/","section":"Tags","summary":"","title":"JNI"},{"content":"","date":null,"permalink":"/en/tags/ndk/","section":"Tags","summary":"","title":"NDK"},{"content":"","date":null,"permalink":"/en/categories/ndk/","section":"Categories","summary":"","title":"NDK"},{"content":"","date":null,"permalink":"/en/tags/command-line/","section":"Tags","summary":"","title":"Command line"},{"content":"","date":null,"permalink":"/en/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"","date":null,"permalink":"/en/categories/linux/","section":"Categories","summary":"","title":"Linux"},{"content":"Preface #In the beginning stages of a project, it is common to encounter various file operations, copying header files, libraries, batch renaming, and so on. Once the file structure is complex, this will be a boring job.\nFind the files #find searches for files in the directory structure, which is how it is described inside man. So how do you search? There are various ways, by file time, by size, by filename, by pathname, by file type, by permissions, by user. These methods can be combined with or without logic to accomplish more demanding searches, which is a boon to file searching. Usually, the introduction of a command starts with a command, find, in the following format\nfind [-H] [-L] [-P] [-D debugopts] [-Olevel] [starting-point...] [expression] [-H] [-L] [-P] [-D debugopts] [-Olevel] it doesn\u0026rsquo;t matter. [-H] [-L] [-P] it\u0026rsquo;s for soft link, not commonly used.[-D debugopts]is to display additional information during the run, information that is too cluttered and mixed to be of much use.[-Olevel]On the other hand, it is used to optimize the lookup, and the default is sufficient, so there is no need to go deeper. The biggest magic of find is in the [expression] at the end, and the following is an example of how this [expression] actually plays with, with the original file structure as follows\n├── alice.h ├── andy │ ├── jack │ │ └── mary.h │ ├── mark.cpp │ ├── mark.h │ └── pony.txt ├── andy.c ├── bill.cpp ├── bill.h ├── mark.h └── mary Now, I want to find the file named andy, what should I write the command. Intuition tells me it should be something like the following\nfind andy But is the intuition right? Let\u0026rsquo;s look at the output\nandy andy/mark.cpp andy/jack andy/jack/mary.h andy/pony.txt andy/mark.h It only finds the andy directory, not even andy.c, so it seems that we need a way to tell find that we\u0026rsquo;re looking for something that\u0026rsquo;s a file, not a directory, and that option is -type. The option -type takes a parameter immediately after -type, which is commonly taken as d for directories and f for files. Now we need to find files, so we should add the -type f option. But is that enough? If you execute the command, you\u0026rsquo;ll see an error, because the andy at the end is considered to be a path, whereas we\u0026rsquo;re looking for a filename. So, we need the help of another option, -name. -name can be followed by a specific name or a regular. Combining these two conditions, we arrive at the final command\nfind -type f -name \u0026#34;andy*\u0026#34; Two things are worth noting here, first of all -type and -name are actually two separate options that can be used individually or in combination, and when used in combination, when they are not connected by an operator (-o(Or), -a(AND),-not), -a alone is used as a concatenation, which means that all the conditions are met before they appear back in the the final result. From this, a reverse lookup method can be extended that\nfind -type f -not -name \u0026#34;andy*\u0026#34; This command will then find all files that do not start with andy.\n./andy/mark.cpp ./andy/jack/mary.h ./andy/pony.txt ./andy/mark.h ./bill.h ./bill.cpp ./mark.h ./alice.h Another point worth noting is that \u0026quot;andy*\u0026quot; is enclosed in double quotes because * is a special character, so it needs to be enclosed in double quotes; if there were no special characters, there would be no need for double quotes. Going back to the original command, why didn\u0026rsquo;t the first command we took for granted find the target we were hoping for? Because find is a strict match, we only wrote andy and left out the suffix .c, which is the easiest place to make a mistake. In fact, by this point, we\u0026rsquo;ve learned 50% of this command, so what\u0026rsquo;s in the rest? Remember the main function of find, which mentions a directory structure? That\u0026rsquo;s right, find can also control the scope of the search.\nHere comes a new requirement, how to find all direct sub .h files in a certain directory? Here direct and child together means that the scope of the search can only be the current directory, not the subdirectories of the current directory. Before solving this problem, we need to know one thing - there are two kinds of interrelationships between two directories, brother or father and son. A brother directory has the same depth, while a parent-child directory has a depth difference of 1. Knowing this, let\u0026rsquo;s look at the requirements - .h files are simple enough to be satisfied using -name \u0026quot;*.h\u0026quot;. However, this will find .h files in the andy directory, so we need something that controls the level of directory lookup, and they are -mindepth, maxdepth. These two parameters are not the same as the previous ones, they belong to Global options. What\u0026rsquo;s meant by Global options is that they are global in their effect, and they always return true, which means that they are only considered in conjunction with other options. And, to emphasize their global nature, they must be written at the top of the command, otherwise a warning will be triggered. As below, they are written before -name \u0026quot;*.h\u0026quot;.\nfind -maxdepth 1 -name \u0026#34;*.h\u0026#34; These two parameters are a bit counter-intuitive, can be understood in this way - up to where to find a maximum, there is a maximum, is maxdepth, the reverse is from where to start looking, is mindepth.\nAfter talking about the directory structure, the name of these obvious parts, the file also has access (access) create (create), modify (modiffy) time, permissions (permission), the size (size) of these are not involved, and these can be used as a find find conditions, before you start, there are some small Before we get started, there are a few rules to do a quick grouping of these options - the options will start with the first letter of the attribute, such as\nTime-related options are time and min, which denote the n days and n minutes before an event occurs, respectively, where an event can be replaced by a (access) ccreate, mmodify, which combine to make a complete option, e.g., mmin n would means to look for files that have been modified within n minutes. By analogy, i stands for case-sensitive, as in iname, l for link files. Of course, these may not be used much, the actual use to check again may also be more convenient, but there are two very good options have to talk about. Consider the following scenario, one day old Ben sent a bunch of user log files, let you give these users according to the frequency of use of grading, what should you do? First of all, we can use the size of the log file as a basis, according to the largest and smallest division of a good interval, such as (0-100M), and then set a good level (such as 5 levels) divided into intervals of each level (0-20, 20-40, \u0026hellip; ) , so that we run the command several times and get all the grading. The idea is wonderful, but does find provide that option yet? It provides -size n. Let\u0026rsquo;s try to find files in the 0-20 range\nfind -size 20M Enter, and you\u0026rsquo;ll see that the results don\u0026rsquo;t seem to be exactly right, it may have found some files that meet the conditions, but not some that do, so what\u0026rsquo;s the problem? It turns out that the n in -size n is a strict match, that is, if you enter 20M, it will only find files that happen to be 20M, not 20M and 20M or so as we expect. So is there a solution, of course there is, is the number in front of the +, - sign, + means greater than or equal to the value, - means less than. So our command to find files under 20M should be\nfind -size -20M Having resolved the issue of sign, there is also the issue of units which is worth noting, namely the M in -20M. Actually, the standard form of -size is -size [+-]n[cwbkMG]. [+-] and n are stated, and those that follow are units. They are listed in increasing order of size and are described as follows\nc: byte w: double byte, also known as word. b: block of 512 bytes, this is the default if the number n is not followed by units k: 1024 bytes, also known as kb M: 1024 * 1024 bytes, i.e. Mb c: 1024 * 1024 * 1024 bytes, i.e. Gb Having said that about units, let\u0026rsquo;s move on to come out with a 20 - 40 grading, do we change 20 to 40 directly? Of course not, changing it to 40 finds files less than or equal to 40M, so we need an interval calibration method. find doesn\u0026rsquo;t provide direct option support, but as I said before, the options are combinable, that is, we can reuse -size to identify an interval. That is, something like the following\nfind -size +20M -size -40M According to this method, change the value many times, you can complete the task. In fact, there is still a little mistake in the above scheme, that is, we did not find out the users who have not used it, that is, the size is 0, then change the number to 0, can we? The answer is yes, but if we want to find empty directories instead of empty files, -size can\u0026rsquo;t solve the problem, because usually the size of empty directories is not 0. So, find provides an option -empty to detect whether a file is empty, which can not only find empty files, but also empty directories. In our example, using find -size 0 finds the following results\n./andy/mark.cpp ./andy/jack/mary.h ./andy/pony.txt ./andy/mark.h ./andy.c ./alice.h The empty directory mary was not found. Instead, a search using find -empty resulted in the following\n./mary ./andy/mark.cpp ./andy/jack/mary.h ./andy/pony.txt ./andy/mark.h ./andy.c ./alice.h Not only was the mary empty directory found, but other empty files were found as well. At this point, find related things have been understood almost. However, in many cases, just finding is not enough to satisfy our needs, we may need to copy the found files to other places or delete them, can we combine these operations? That\u0026rsquo;s where our xargs comes in.\nxargs #xargs只有一个简单的功能，就是从标准输入读入内容，构建并执行命令。怎么理解呢？假设我们在执行find命令，find命令执行肯定是有过程，有逻辑的。按照一定的逻辑和过程，find对文件进行逐一评估，假如满足条件，就输出结果。随着命令的执行，结果可能越来越多。假如我们需要对产生的每个结果都执行一条命令呢，这该怎么办？按照一般的思路，当然是将结果保存起来，然后再写个脚本，读取每一条记录，然后执行相应。但是有了xargs，我们不用这么麻烦了，可以一步到位。我们利用管道符将结果从终端连接到xargs中，xargs接收到一条信息，就会将它作为构建命令的参数，就好像我们手动输入了命令那样，构建完成后还会自动执行。最终的结果就是，没产生一个输出，就会产生一条以这个输出为参数的命令，并且这条命令还自动执行，最终的效果就是实现了一条命令实现了多个功能。\nCombining find with xargs #Now that we are challenged to upgrade, there is a requirement to extract all the header files in a directory to another directory. This requirement can be divided into two parts, one part is to find the header files, which can be done with the find command. The other part is to copy the found header files, which requires the involvement of xargs.\nThe first step is to find the header file. A header file is a file ending in .h (ignoring .hpp for the moment), and this suffix appears in the name, so we can use the -name \u0026quot;*. h\u0026quot; option, and in order to avoid interference with certain directory names, we will qualify the type as well -type f to look for files only. This completes the first step. The second step is to copy the file. The standard way to copy a file is as follows\ncp [OPTION]... SOURCE... DIRECTORY According to the format of this command, we need to determine a few parameters, the source file is of course the file we find, which will be left aside for now. The destination folder is where we copy to, so let\u0026rsquo;s just create a new test directory for now, and the destination folder is test. Is that the end of the story? Header files often need to form a dependency path with their parent directory, so it\u0026rsquo;s not a good idea to copy all the header files directly into the test directory, as this will mess up the header file dependencies, and we\u0026rsquo;ll have to copy the parent directory associated with the header file. As it happens, cp provides the option -parents - which copies the completion filenames of the source files, i.e. the containing directories. So the crux of the matter comes down to the source file parameter.\n","date":"18 February 2022","permalink":"/en/post/Linux%20batch%20file%20manipulation%20-%20based%20on%20find,xargs.html","section":"Posts","summary":"Preface #In the beginning stages of a project, it is common to encounter various file operations, copying header files, libraries, batch renaming, and so on. Once the file structure is complex, this will be a boring job.\nFind the files #find searches for files in the directory structure, which is how it is described inside man.","title":"Linux batch file manipulation - based on find,xargs"},{"content":"","date":null,"permalink":"/en/tags/shell/","section":"Tags","summary":"","title":"shell"},{"content":"","date":null,"permalink":"/en/tags/css/","section":"Tags","summary":"","title":"CSS"},{"content":"","date":null,"permalink":"/en/tags/frontend/","section":"Tags","summary":"","title":"FrontEnd"},{"content":"","date":null,"permalink":"/en/categories/frontend/","section":"Categories","summary":"","title":"FrontEnd"},{"content":"Preface #Not long ago, in one of my projects, I need to show a horizontal scrolling tab, which supports horizontal mouse drag and click to switch. In the process of realization, I found that this small feature needs to use the front-end of the three carriages at the same time, but the realization of the difficulty is not high, and the final result is not bad, is a rare beginner project, so the idea of writing this article was born, I hope that beginners can help. At the same time, in order to avoid beginners to learn the framework, I intend to use a purely native way to realize it.\nOur final result should be similar to the following: ! last_version\nRequirements analysis #Requirements analysis is to refine the functions we need to complete, the completion of a certain function requires the participation of which technology. For beginners, requirement analysis is crucial, it can help us clarify our thoughts and find a breakthrough to solve the problem, so it should be given enough attention. Taking the goal of this article as an example, the requirement analysis of the tab page can be like the following:\nthe main body of our display is the tab page, HTML is the main technology to achieve the main body; tabs need to be able to drag and click, which involves listening to mouse events and processing, is the home of JS; since the tabs can be dragged, is it necessary to hide that ugly scrollbar, add an activity indicator, and give the mouse a different style? Obviously, these are the strengths of CSS. As above, through the display, operation, style of the division, we further clarify the HTML, JS, CSS need to complete the work, and even the realization of the clear, so the more detailed the demand split, the more control over the implementation.\nBasic framework #For the front-end, HTML is always the source of everything, so a word first construct a standard HTML page is always right. For demonstration purposes, I\u0026rsquo;ve put everything in one HTML file with the following structure\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Tab Demo\u0026lt;/title\u0026gt; \u0026lt;!-- This is the style area where the subsequent css code will be added. --\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- This is the page area where the subsequent HTML code will be added to --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;!-- Here is the script area, the subsequent JS code will be added here, placed here because of the convenience of writing code --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; Here, unlike in the past, I\u0026rsquo;ve put script at the end, this is because I want the page tag to be directly available when writing the script, reducing complexity by listening to the page load.\nImplemente the basic function #With the basic structure, the next step is of course to draw the page. It is not difficult to see from the effect of the picture, the page mainly consists of a tab, for HTML, this is not a list of it. So, the breakthrough appeared, we first to the HTML inside the list added\n\u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;肖申克的救赎\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;霸王别姬\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;阿甘正传\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;泰坦尼克号\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;这个杀手不太冷\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;美丽人生\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;千与千寻\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;辛德勒的名单\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;盗梦空间\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;忠犬八公的故事\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; So we had the original tabs. But the tabs were vertical and had ugly little black dots that didn\u0026rsquo;t fit the bill. Having identified these problems, the next step is of course to solve them, which is of course the strong point of CSS. The first problem is to make the list horizontal. The first problem is getting the list to go sideways, which changes the relative position of the elements, and corresponds to the layout function of CSS. Speaking of layout, there are a number of CSS layout methods, such as float, position, and so on. Tabs are arranged horizontally in close proximity, one next to the other, so of course you use flex. As for the pesky little black dots, this is something new and I need to look it up. I found that ul has an attribute list-style-type, just set it to none to get rid of the black dots. At this point, all the tabs on the page are tightly aligned. To make it more like a tab, you need to center it, limit the width, add a background color, and add some padding. here\u0026rsquo;s the code after changing the style\nul{ display: flex; justify-content: center; align-content: center; list-style-type: none; background-color: #2397f3; width: 600px; overflow-x: scroll; } li{ padding: 16px; flex-shrink: 0; } There are two things worth noting. In the ul style, because of the width constraints placed on the ul, it goes outside the content area, so add the overflow-x attribute to the ul. Also due to the width, the flex child item will shrink by default if the width is not enough, which is shown on the label as the text line break, flex-shrink: 0; is to let the child item retain its original size. At this point, refresh the page again, you can see the basic shape of the tab has come out. It\u0026rsquo;s rudimentary, but you can drag the scrollbar to scroll left and right. Next, our goal is to remove this ugly scrollbar. Search online, found that Firefox, IE and Chrome are not the same way, for compatibility, we will write to all.\nul{ scrollbar-width: none; /* Firefox */ -ms-overflow-style: none; /* IE 10+ */ } ul::-webkit-scrollbar { display: none; /* Chrome Safari */ } After the scrollbar is removed, the UI looks good, but a new problem arises - the tabs don\u0026rsquo;t scroll anymore. Don\u0026rsquo;t worry, the next step is to add mouse dragging functionality.\nImplemente the interaction #In the browser, HTML tags have the ability to listen to system events, and responding to these events allows the page to respond to user actions in real time. Through the combination of different events, you can realize a variety of rich, interesting features, tabs are the same.\nThe primary function of the tab is to scroll elements with the mouse drag , then, the first task is to listen to the mouse\u0026rsquo;s movement events . But just listen to the movement is not enough, because usually, the user in the left mouse button down before you want to really drag, the left mouse button up after the end of the drag. So, this drag action actually requires a combination of mouse down (mousedown), mouse move (mousemove) and mouse up (mouseup) events. So where and how do you add these three methods?\nIn the Web API, the entry point for JS to manipulate HTML is the Document object, which provides an API for manipulating (adding, deleting, modifying, or changing) HTML elements.There is a standard process for this.\nFind the target element through Document. 2; Perform element and style changes on the target element. 3; Changes are made; The process is repetitive and tedious, and in order to reduce the need to write such sample code and speed up development, a whole bunch of front-end frameworks have come into existence. So, when learning about front-end frameworks, keeping this basic step in mind will help you quickly understand how the frameworks work. After all, no matter how the framework changes, it is ultimately the process that is implemented.\nOnce the algorithm is clear, the next step is the concrete implementation.\nFind target element #Before finding the target, it needs to be clear who the target is in the first place. The user certainly doesn\u0026rsquo;t want to drag the mouse elsewhere on the page and have the tab scroll along, which is weird. So our target element should be an unordered list. So, how to know the unordered list through Document? Checking the API of Document, I found that it has a querySelector method, which will find the selector that satisfies the condition from top to bottom and return the first element that satisfies the condition, and the parameter is the name of the selector. We\u0026rsquo;ve already made it clear that our target is an unordered list, so the final code to find the target element looks like this\nconst ul=document.querySelector(\u0026#39;ul\u0026#39;); Let the list scrollable #Every HTML element is an Element object in JS. In the previous step we have got an Element object ul, note that the ul object here is not exactly the same as the ul tag. One is a JS object representation of an HTML tag and the other is an HTML tag. Now that you have an object, you can manipulate that object by calling the appropriate methods. By consulting the Element object\u0026rsquo;s API, I found that it has an addEventListener() method, which accomplishes listening to certain events for the HTML tag represented by the object. This method takes two parameters, the first of which is the name of the event, as described in the previous section. The second parameter is the handling of this event, and this is where we realize the magic.\nFirst, after the user presses the left mouse button, it starts recording the mouse movement. After the left mouse button is lifted, the logging stops. So the main function of the press and lift is to maintain the logging switch, and the action of controlling the scrolling of the label has to be handled in the mouseover callback.\nBut before actually writing the logic, there are still two issues that have not been dealt with. 1, how to make the label scroll? 2. How to write the scrolling logic? Question 1 of course, you need to consult the Element API. Searching for scrolling related, I found two methods that are more relevant \u0026ndash; scrollBy(), scrollTo(), both of them can scroll the content. The only difference is that the former\u0026rsquo;s parameter is the offset of the scroll, and the latter is the final value. Since mouse movement is bit by bit, it\u0026rsquo;s a bit easier to choose the former. Determined the method, but also answered the first question. For question two, it\u0026rsquo;s simply a matter of how to provide the parameters needed for question one. scrollBy() takes two parameters, the horizontal and vertical scroll offsets. Since we only want the tab to scroll horizontally, the vertical offset is always 0. What about the horizontal? Usually event callbacks pass an event object called MouseEvent, we check the API of the event object and find that it comes with several properties about coordinates - clientX, movementX, screenX. The movementX is straight forward for our needs, it represents the offset between the last mouse movement and this one, and it just so happens that scrollBy() takes the offset as its parameter, so there you go. To summarize, this is the following code\nconst ul=document.querySelector(\u0026#39;ul\u0026#39;); let isMouseDown=false; ul.addEventListener(\u0026#39;mousedown\u0026#39;,(e)=\u0026gt;{ isMouseDown=true; }) ul.addEventListener(\u0026#39;mousemove\u0026#39;,(e)=\u0026gt;{ if(isMouseDown){ ul.scrollBy(-e.movementX,0); } }) ul.addEventListener(\u0026#39;mouseup\u0026#39;,(e)=\u0026gt;{ isMouseDown=false; }) As you can see, a negative sign is added to the offset in the handling of mousemove. This is because the top-left corner of the HTML page is the coordinate origin, and the right side is the positive direction of the X-axis. If you move all the way to the right, the X coordinate is increasing, and the value of movementX is the difference between the current mouse coordinate and the last coordinate point, which must be smaller than this one, so the difference between the two must be positive. For the same reason, a positive value for the scrollBy() parameter means an increase in the X value, i.e., it shows the content on the right and hides the content on the left. The effect of combining the two is that dragging the mouse to the right shows the hidden content on the right side of the tab, which is counter-intuitive. Normally we want to drag the mouse to the right to show the left side of the page and hide the right side. Based on this analysis, we need to invert the value of movementX.\nShow currently selected tabs #Right now, the tabs are scrollable, but not yet selected. I want a small horizontal bar to appear below a tab when I click on it to indicate the selected state. Obviously, displaying the little bar is a CSS issue, and clicking on the tab to toggle the little bar is a JS issue, so this time we need to deal with both JS and CSS.\nFirst of all, let\u0026rsquo;s display the small bar. There are two ways to do this, one is to have a div tag in the HTML, the other is to use a ::after pseudo-element. I chose the latter, which keeps the HTML clean. Next you need to style the little horizontal bar\nOverlay on the selected tag Positioned at the bottom of the tag As long as the label We know that normal HTML document flow is left-to-right, top-to-bottom, with newly added elements appending to the right or bottom of existing elements. The small horizontal bar needs to be overlaid on the tag, so this default behavior has to be changed, and the position attribute is the key to making this happen. The absolute and fixed attributes can be used to break out of the normal document flow and cause an element to overlay an ancestor element, the difference being that the former is relative to the closest positioned ancestor, while the latter is the viewport equivalent. The small horizontal bar follows the label display, so obviously the former should be used. Having determined the position, there is also the size and style. Since we\u0026rsquo;re using absolute positioning, bottom, left, and right define its position and size accordingly, and we\u0026rsquo;ll just use border-bottom for the style of the little bar. So, the style of the small bar is confirm now\n.current::after{ content: \u0026#34;\u0026#34;; position: absolute; border-bottom: 4px solid #FFC109; border-radius: 2px; bottom: 0; left: 0; right: 0; } Is it over, not yet! When you use absolute positioning, you must always remember to find an anchor point, or reference, for the absolutely positioned element, otherwise top, left, right, bottom to refer to whom? So how do you tell the absolutely positioned element what to refer to, it\u0026rsquo;s the position attribute. Only this time it\u0026rsquo;s going to be inside the CSS of the reference. And from the previous styling analysis, the little horizontal bar always follows the tab, which means the reference for the little horizontal bar is the tab. So, there\u0026rsquo;s also the position attribute to add to the tab\u0026rsquo;s style. And of course, I changed the color a bit to make the distinction more obvious.\n.current{ color: white; position: relative; } At this point, the small horizontal bar can be displayed normally.\nSmall horizontal bar following mouse clicks #With the experience of the previous drag-and-drop functionality, this time it\u0026rsquo;s a breeze. When the mouse clicks on a tab, a small bar is displayed below the corresponding tab. This time the object of the event is a single tab, so the click event is added to a single tab. But this time there are too many tabs, we can\u0026rsquo;t follow the previous Find-Set method, it\u0026rsquo;s too cumbersome. Coincidentally, we\u0026rsquo;ve already got the ul object, and with its children property, we can get all the lis. The little bar has to be switched to a different tab, which means that the style of the little bar has to be dynamically added or removed depending on who is clicking on it. Checking the Element API, I found that there is a className property, change its value to increase or decrease the style.\nlet last=null; for(let l of ul.children){ l.addEventListener(\u0026#39;click\u0026#39;,(e)=\u0026gt;{ if(last){ last.className=\u0026#39;\u0026#39;; } e.target.className=\u0026#39;current\u0026#39;; last=e.target; }) } The implementation of the code has an extra last object. Because normally only one tab can be selected at a time, when a new tab is selected, the last selected tab should be restored to its original style, which is what the last object does. We uncheck the last element first, and then check the currently clicked object, which completes the effect of the small horizontal bar following the clicked selection.\nSummary #Overall, the difficulty of this project is not how hard it is to implement, but how new it is. Many beginners, in the face of such new problems are often helpless and can not find the entry point. This article tries to analyze the requirements, disassemble the problem, refine the methodology and finally solve the problem in the form of an example with a beginner\u0026rsquo;s mindset. Starting from the most simple intuition, it guides the thinking to find a way that is easy to accept and understand.\nTherefore, do not panic when encountering a new problem, after the problem is disassembled, see if you can find a breakthrough, if you can not find, and then look for inspiration from the several main objects involved, usually will have some gains. Last but not least, visit MDN more often, it can really come in handy at critical moments.\nFinally, Happy Valentine\u0026rsquo;s Day, and may all lovers be united in love!\n参考\n[1] 使用CSS隐藏元素滚动条 [2] Element [3] Events [4] MouseEvent ","date":"12 February 2022","permalink":"/en/post/horizontal%20scrolling%20tabs%20with%20plain%20HTML,%20JS,%20CSS.html","section":"Posts","summary":"Preface #Not long ago, in one of my projects, I need to show a horizontal scrolling tab, which supports horizontal mouse drag and click to switch. In the process of realization, I found that this small feature needs to use the front-end of the three carriages at the same time, but the realization of the difficulty is not high, and the final result is not bad, is a rare beginner project, so the idea of writing this article was born, I hope that beginners can help.","title":"horizontal scrolling tabs with plain HTML, JS, CSS"},{"content":"What is JNI #The full name of JNI is Java Native Interface, and as the name suggests, it\u0026rsquo;s a programming method that solves the problem of Java and C/C++ calling each other. It really only solves two aspects of the problem, how to find and how to access. Figure out these two topics and we have learned JNI development.It should be noted that JNI development involves only a small part of the C/C++ development knowledge, when we encounter a problem we first need to determine whether it is a C/C++ problem or a JNI problem, which can save a lot of time searching and locating.\nLook at function calls through the eyes of the JVM #We know that the Java program can not run alone, it needs to run on the JVM, but the JVM needs to run on the physical machine, so it is a very heavy task, both to deal with the Java code, but also to deal with a variety of operating systems, hardware and other issues. It can be said that understanding the JVM, you understand all of Java, including, of course, JNI. so let\u0026rsquo;s start as a JVM to see how the Java code is running it (just rough content, omitted a lot of steps, in order to highlight the part we care about).\nBefore running Java code, a JVM is started.After the JVM is started, some necessary classes are loaded.These classes contain a class called the main class, that is, a method containing a static member function with the function signature public static void main(String[] args). Once the resources are loaded, the JVM calls the main method of the main class and starts executing Java code. As the code executes, one class relies on another, layer upon layer of dependencies that work together to complete the program\u0026rsquo;s functionality. This is the approximate workflow of the JVM, you can say that the JVM is like a bridge, connecting the Java mountain and native mountain.\nNow the question arises, in a Java program, a class needs to access something outside the JVM via JNI technology, so how does it need to tell me (I am now the JVM)? There needs to be a way to mark normal Java methods as special, and that marking is the native keyword (Kotlin has its own keyword, external, although you can use this keyword when using Kotlin). When I execute the method and see that it is marked differently, I look for the executable elsewhere instead of inside the Class, which is a JNI call. That means that for a Java program, just marking a method as native and calling that method where it is needed will complete the JNI call. But for me, what to do with this one JNI call? Actually the above process of finding the executable is a jump problem, and in the world of C/C++, a jump problem is a pointer problem. So where should this pointer it point to?\nC/C++ code is a combination of functions (Java methods will be abbreviated directly to methods below, while C/C++ functions will be abbreviated directly to functions), each of which is a pointer, a property that is just right for my needs. But for me, there is such a big world out there that I don\u0026rsquo;t know where, and what to look for, and the information given to me is still not enough. To limit the scope, I made it so that I would only look for functions loaded via System.loadLibrary(\u0026quot;xxx\u0026quot;), the rest I would just strike (throw an error). This instantly lightens my workload, at least I know where to look.\nHaving determined the scope, the next step is to determine the real target in this scope.How to uniquely identify a class in the Java world? Some people will blurt out the name of the class, which is not entirely correct, because the class name may be renamed, we need to fully-qualify the class name, that is, the package name plus the name of the class, such as the fully-qualified class name of String is java.lang.String, the class name is java.lang.String. class name is java.lang.String. But what does this have to do with looking up native methods. Of course there is a connection, since a fully qualified class name is unique, then its methods are also unique, so if I stipulate that the fully qualified class name plus the method name of the class is the function name of the native function, then I can find the native function by the way of the function name, the answer is yes, but there is a flaw because the Java system supports method overloading, that is, within a class, a method with the same name can be overloaded with the same name, so that the method will be overloaded with the same name. That is, inside a class, there may be more than one method with the same name. So what is the condition that constitutes overloading, is the parameter list is different. Therefore, the result is obvious, I added the parameter list on the basis of the previous, combined into a lookup conditions, I am not the only one can determine a native function it is JNI static registration.\nHowever, since I only need to determine where the pointer is pointing, can I just assign a value to the pointer instead of looking it up every time, which I don\u0026rsquo;t know is tiring, but it\u0026rsquo;s still time-consuming. Of course I\u0026rsquo;m satisfied with this kind of need. If you tell me directly, I won\u0026rsquo;t look for it, and I\u0026rsquo;m happy to do so. Moreover, since you have found me, I don\u0026rsquo;t need to lay down so many rules, all let go, you say it is I believe you it is. This is the dynamic registration of JNI.\nJNI function registration #In the previous section, we learned about the origins of JNI function registration by incarnating the JVM and introduced two types of function registration. From the examples, we can also summarize the characteristics of the two registration methods\nRegistration Type Advantages Disadvantages static registration automatic JVM lookups simple to implement long, restrictive function names time-consuming lookup dynamic registration fast running no restriction on function name complex implementation So how exactly do you do it? Let\u0026rsquo;s move on.\nStatic registration #Although static registration is more restrictive, they are shallow rules that are easier to implement, so let\u0026rsquo;s start with static registration first.\nStatic registration has clear development steps\nWrite Java classes that declare `native\u0026rsquo; methods. Use java xxx.java to compile Java source files into class files. Use javah xxx to generate the corresponding .h file. Introduction of the .h file in the build tool Implementation of functions in .h files The above steps are the basic steps of static development, but in fact, in front of today\u0026rsquo;s powerful IDE, these do not need us to do it manually, in Android Studio, after defining native method, press alt + enter on the method to generate the correct function signature, and directly write the function logic. But to learn a subject, we still need to take a truthful and realistic attitude, so I will use an example to illustrate these rules to deepen the reader\u0026rsquo;s understanding.\nTest.java\npackage me.hongui.demo public class Test{ native String jniString(); } native-lib.cpp\n#include \u0026lt;jni.h\u0026gt; extern \u0026#34;C\u0026#34; jstring Java_me_hongui_demo_Test_jniString(JNIEnv *env, jobject thiz) { // TODO: implement jniString() } The above is an example of a JNI function declared on both ends, and it\u0026rsquo;s not hard to see that the\nFunction signatures prefixed with Java_ The prefix is followed by the full path of the class, i.e., it contains the package name and the class name. _ as path separator The first argument to a function is always of type JNIEnv *, and the second argument varies according to the type of the function; a method of type static corresponds to type jclass, otherwise it corresponds to type jobject. The type system will be expanded in detail later. Why Java method corresponds to C/C++ function, there will be two more parameters. We know that the JVM is multi-threaded, and our JNI methods can be called in any thread, so how to ensure that before and after the call JVM can find the corresponding thread, this is the role of the first parameter of the function, which is a kind of encapsulation of the environment of the thread, and the one-to-one correspondence with the thread, which means that you can not use a thread of the JNIEnv object in another thread. In addition, it is a window for C/C++ to access the Java world, and the vast majority of JNI development is dealing with JNIEnv.\nDynamic registration #Again following the development process, let\u0026rsquo;s go through it step by step. We change the name of the Java_me_hongui_demo_Test_jniString function in the previous section to jniString (of course it\u0026rsquo;s OK if we don\u0026rsquo;t change it, there\u0026rsquo;s no restriction after all), and the parameter list stays the same, and at this point, we find that the Java file reports an error saying that the local method is not implemented. Actually, we did implement it, just that the JVM can\u0026rsquo;t find it. In order for the JVM to find it, we need to register it with the JVM. So how and where do you register, it seems everywhere and nowhere. As mentioned earlier, the JVM will only look for libraries loaded via System.loadLibrary(\u0026quot;xxx\u0026quot;); , so in order to use a native method, you first have to load the library file that contains the method first, and after that, you can use it. Having loaded the library indicates that the Java program is going to start using native methods. After loading the library, before calling the method, theoretically, you can register the method, but how to determine the timing, JNI has long been arranged for us.JVM in the library loaded into the virtual machine, it will call the function jint JNI_OnLoad(JavaVM *vm, void *reserved), in order to confirm the version of the JNI, the version of the information will be passed to the JVM in the form of return value The version information will be passed to the JVM as a return value. Currently, the available values are JNI_VERSION_1_1,JNI_VERSION_1_2,JNI_VERSION_1_4,JNI_VERSION_1_6. If the library does not define this function, then the default return is JNI_VERSION_1_1 and the library will fail to load, so we usually return the higher version in order to support the latest features. Now that we have such a good time to register, the next step is to implement the registration.\nBut things are not that simple. From the JNI_OnLoad function parameter list, it is clear that, at the moment, the only thing available is the JVM, but checking the JVM\u0026rsquo;s API, we don\u0026rsquo;t find a function for registering - the registration function is written inside the JNIEnv class. As it happens, the JVM provides functions to get JNIEnv objects.\nJVM has several functions related to JNIEnv, in Android development, we need to use AttachCurrentThread to get the JNIEnv object, this function will return the execution status, when the return value is equal to JNI_OK, it means that the acquisition is successful. With the JNIEnv object, we can register the function.\nLet\u0026rsquo;s start with the declaration of the register function - jint RegisterNatives(jclass clazz, const JNINativeMethod* methods,jint nMethods. The return value is, needless to say, the same as AttachCurrentThread, indicating the execution state. The difficulty is in the parameters, the first parameter is of type jclass and the second is a pointer to JNINativeMethod, both of which are unseen mains.\nWhy do you need so many parameters? Doesn\u0026rsquo;t the JVM only need a function pointer. Or the problem of uniqueness, remember the previous static registration, static registration with a fully qualified type and method, parameter list, return value of the combination to determine the uniqueness of the function. But for dynamic registration, these are all unknown, but necessary. In order to determine these values, it can only be done in other ways. The jclass is the scope of existence of the qualified method, and the way to get the jclass object is simple, using the jclass FindClass(const char* name) function of JNIEnv. The argument needs to be the string-qualified class name, and replace . replaced by /, that is, similar to the form of me/hongui/demo/Test, why write this way, later will take a separate section out of the details.\nThe second and third parameters combined are the common form of array parameters. Let\u0026rsquo;s start with the definition of JNINativeMethod.\ntypedef struct { char *name. char *signature. void *fnPtr. } JNINativeMethod. There\u0026rsquo;s a trick to writing a function where the correlation is from the Java side to the C/C++ side, in order of definition. The name is the name of the native function that corresponds to the Java side only, this is purely a Java side thing, whatever the name is on the Java side is the name here. The second signature represents the signature of the function, which consists of a list of parameters and a return value, such as (I)Ljava/lang/String;, this signature is related to both sides. First, the native method on the Java side defines the type of the parameter list and the return value, that is, it limits the form of the signature. Secondly, Java\u0026rsquo;s data types need to be converted to C/C++ here, that is, the parameter list and return value need to be written in C/C++ form, which is related to C/C++. The last one, fnPtr, is a function pointer, which is purely C/C++, and represents the C/C++ implementation of the native method on the Java side, that is, the jump pointer mentioned above. Knowing all this, we still can\u0026rsquo;t write code, because, we still have the core of JNI left unsaid, that is, the type system.\nJNI\u0026rsquo;s type system #The type system of JNI is messy due to the two language systems involved, Java and C/C++, but it is not untraceable. The first thing that needs to be made clear is that both ends have their own type systems, boolean, int, String in Java, bool, int, string and so on in C/C++, which unfortunately don\u0026rsquo;t correspond one to the other. In other words, C/C++ does not recognize Java\u0026rsquo;s types. Since the types are not compatible, how can we call them. This is the problem that JNI is trying to deal with.\nJNI type mapping #In order to solve the problem of type incompatibility, JNI introduces its own type system, which defines types compatible with C/C++, and also specifies the type conversion relationship from Java to C/C++. Here\u0026rsquo;s a table showing how the conversion works\nJava Types C/C++ Types Description boolean jboolean unsigned 8 bits byte jbyte signed 8 bits char jchar unsigned 16 bits short jshort signed 16 bits int jint signed 32 bits long jlong signed 64 bits float jfloat 32 bits double jdouble 64 bits void void N/A At first glance, there is nothing special, but just add j prefix (except void), but this is only the basic type, we should not forget that Java is a pure object-oriented language. Complex objects of all kinds are the main battlefield of Java. And with complex objects, things get complicated. We know that in Java, any object is a subclass of the Object class. So can we except the above basic types of all complex types are treated as Object class object to deal with it, but can, but not convenient, such as arrays, strings, exceptions and other common classes, if you do not do the conversion to use the more cumbersome. In order to facilitate our development, JNI will be complex types are divided into the following cases\njobject (all Java objects) | |--jclass (java.lang.Class) |--jstring (java.lang.String) |--jarray (array) || || jobjectArray (Object array) || jbooleanArray (boolean array) || jbyteArray (byte array) || jcharArray (char array) || jshortArray (short array) || jintArray (int array) || jlongArray (long array) || jfloatArray (float array) || jdoubleArray (double array) |--jthrowable (java.lang.Throwable exception) The two tables together are the type conversion relationship from the Java side to C/C++. That is to say, when we declare native code in Java, the correspondence between native function parameters and return values is also the correspondence between C/C++ calling Java code parameter passing. But after all, the two systems are still separated, the type system only defines the compatibility way, and does not define the conversion way, the two sides of the parameter still can not recognize each other, so the JNI and a type signature, want to deal with the type of automatic conversion problem.\nType signatures for JNI #Type signatures are similar to class type mappings in that there are correspondences, so let\u0026rsquo;s look at a correspondence table.\nType Signatures Java Types Z boolean B byte C char S short I int J long F float D double L fully-qualified-class ; fully-qualified-class [type type[] (arg-types)ret-type method type For basic types, it\u0026rsquo;s also simple to take the initial letter, except for boolean (the initial letter is taken by byte), and long (the letter is used as a prefix identifier for conforming objects). The important thing to note is the case of a composite type, i.e., a class. Its signature consists of three parts, the prefix L, the fully qualified name of the type in the middle, followed by the suffix ;, all three of which are missing, and the qualifier separator is replaced by a /. Note that type signatures and type systems are not the same concept. Types are usually plain strings that are used by the JVM in places like function registration. A type system is the same as a normal type, where variables can be defined and used as parameter lists by the user. Additionally, array objects have their own type signature, also with the type prefix [ followed by the type signature. The final method type, which is what we\u0026rsquo;re going to talk about next, also consists of three parts: the () and the parameter list inside the (), and the return value after the (). All the types used here refer to type signatures.\nLet\u0026rsquo;s look at an example.\nlong f (int n, String s, boolean[] arr); How does it write its type signature? Let\u0026rsquo;s analyze it step by step\nDetermine its type inside Java, find the correspondence in the table and determine the form of the signature. Determine the type of its components using the methodology of step 1. Putting together the identified signatures This example is a method type, which corresponds to the last item in the table, so the signature is of the form (parameter) return value. The method has three parameters, which we determine one by one in the same way as in step 1.\nint n corresponds to the type int and is signed I. String s corresponds to the type String, which is a composite type corresponding to the penultimate item in the table, so its basic signature takes the form L fully qualified name;. The fully qualified name of String, java.lang.String, becomes java/lang/String after replacing , with /. Putting them together is Ljava/lang/String;, as per step 3. boolean[] arr corresponds to an array type with a signature of the form [type, and boolean has a signature of Z. Combined they are [Z. Finally, the return value, which is of type long, is signed J. Combining this information according to the signature form is (ILjava/lang/String;[Z)J, Note that there is no separator between the type signature and the signature, nor is it needed; the type signatures are tightly packed.\nLook again at dynamic registration #With JNI\u0026rsquo;s type system support, go back and move on to the dynamic registration example and let\u0026rsquo;s go on to refine it.\nGet JNIEnv object with JVM object, i.e. auto status=vm-\u0026gt;AttachCurrentThread(\u0026amp;jniEnv, nullptr); Use the JNIEnv object obtained in step 1 to obtain the jclass object, i.e. auto cls=jniEnv-\u0026gt;FindClass(\u0026quot;me/hongui/demo/Test\u0026quot;); Define the JNINativeMethod array, i.e. JNINativeMethod methods[]={{\u0026quot;jniString\u0026quot;, \u0026quot;()Ljava/lang/String;\u0026quot;,reinterpret_cast\u0026lt;void *\u0026gt;(jniString)}} ;, see the previous section for method signatures here. Call the RegisterNatives function of JNIEnv. That is, status=jniEnv-\u0026gt;RegisterNatives(cls,methods,sizeof(methods)/sizeof(methods[0]));. Of course, don\u0026rsquo;t forget to implement the corresponding native function, i.e. here jniString - the third parameter of JNINativeMethod. These five steps are the template for the implementation of the JNI_OnLoad function in the dynamic registration, the main changes still come from the jclass to get the parameters and JNINativeMethod signatures, etc., must be strictly one-to-one correspondence. Such as the following example\nextern \u0026#34;C\u0026#34; jint JNI_OnLoad(JavaVM *vm, void *reserved){ JNIEnv* jniEnv= nullptr; auto status=vm-\u0026gt;AttachCurrentThread(\u0026amp;jniEnv, nullptr); if(JNI_OK==status){ JNINativeMethod methods[]={{\u0026#34;jniString\u0026#34;, \u0026#34;() Ljava/lang/String;\u0026#34;,reinterpret_cast\u0026lt;void *\u0026gt;(jniString)}}; auto cls=jniEnv-\u0026gt;FindClass(\u0026#34;me/hongui/demo/Test\u0026#34;); status=jniEnv-\u0026gt;RegisterNatives(cls,methods,sizeof(methods)/sizeof(methods[0])); if(JNI_OK==status) { return JNI_VERSION_1_6. } } return JNI_VERSION_1_1; } Using data in JNI #After all the previous grating, it\u0026rsquo;s really only about one thing - how to find it. Although complicated, but the good thing is that there is a trace, the big deal is to run the run. The following to talk about this problem is much more tricky, need a little patience and careful. This part can also be divided into two smaller problems - *** accessing the data of a known object and creating a new object. It is important to mention that the access and creation here are for Java programs, that is, the object exists on the heap of the JVM virtual machine, and our operations are based on the operation of the heap object.*** In C/C++ code, the only way to manipulate heap objects is through the methods provided by JNIenv. So, this part is actually an explanation of the application of JNIenv methods.\nJava object access #When we say accessing an object in the object-oriented world, we usually mean two things; accessing the object\u0026rsquo;s properties, and calling the object\u0026rsquo;s methods. These operations are well implemented in the Java world, but not in the C/C++ world. In the section on JNI\u0026rsquo;s type system, we also learned that complex objects in Java correspond to the class jobject in C/C++, so obviously, no matter how awesome that object is in the Java world, it\u0026rsquo;s treated the same in C/C++. In order to realize C/C++ access to Java\u0026rsquo;s complex objects, combined with the way of accessing objects, JNIEnv provides two major classes of methods, one corresponding to properties and one corresponding to methods. With JNIEnv, C/C++ can realize the goal of accessing objects. There is also a more uniform procedure for using them:\nPrepare the corresponding id (fieldid or methodid) according to the content to be accessed. Identification of the objects to be accessed and the data to be invoked Object access is accomplished through JNIEnv method calls. As you can see, this uses a few more preparation stages (steps 1, 2) than the normal object-oriented approach. As mentioned before, this part of the process requires more patience and care, and less cool maneuvers; after all, there is only so much room to play. This is specifically also reflected in steps 1, 2 above. it is this preparation phase that makes the whole C/C++ code ugly and fragile, but - it\u0026rsquo;s not like it doesn\u0026rsquo;t work, is it?\nLook at an example of a Person class defined in Java with the following class definition\npublic class Person(){ private int age. private String name. public void setName(String name){ return this.name=name; } } Now, how do we access the object of this class in our C/C++ code. Suppose we need to read the age value of this object and set the name value of this object. Based on the above steps, we have the following steps\nPrepare the fieldid of age and methodid of setName. According to the methods of JNIEnv, we can see four related ones, two for fieldid and two for methodid, divided into normal and static ones. We\u0026rsquo;re all about the normal ones here, so the methods identified are GetFieldID and GetMethodID. The first parameter is the jclass object, which is retrieved as described earlier, i.e., through the FindClass method of JNIEnv, with the parameter being the fully-qualified class name, with / replacing . . The last two parameters correspond to the name and type signature of the Java side, age belongs to field, int type signature is I, setName belongs to method, the signature form is (parameter) return value, here the signature of the parameter is Ljava/lang/String;, the signature of the return value is V, the combination is . \u0026quot;(Ljava/lang/String;)V\u0026quot;. Assuming we already have the Person object obj, passed through Java. Two methods need to be called, age is a plastic attribute, to get its value, the corresponding GetIntField method needs to be used. setName is a method that returns a void value. So CallVoidMethod should be used. The above analysis leads to the following sample code.\nauto cls=jniEnv-\u0026gt;FindClass(\u0026#34;me/hongui/demo/Person\u0026#34;); auto ageId=jniEnv-\u0026gt;GetFieldID(cls, \u0026#34;age\u0026#34;, \u0026#34;I\u0026#34;); auto nameId=jniEnv-\u0026gt;GetMethodID(cls, \u0026#34;setName\u0026#34;,\u0026#34;(Ljava/lang/String;)V\u0026#34;); jint age=jniEnv-\u0026gt;GetIntField(obj,ageId); auto name=jniEnv-\u0026gt;NewStringUTF(\u0026#34;ZhangSan\u0026#34;); jniEnv-\u0026gt;CallVoidMethod(obj,nameId,name); From the analysis and examples above, patience and attentiveness are mainly reflected in the\nBe patient in determining the type and name of the property or method to be accessed, and keep the types in the three steps identical. That is, the type of the call to GetFieldID should be consistent with the type of GetXXXField, and the same goes for the method. Be careful with static and non-static modifiers of properties or methods, as static ones usually require the use of a method with the static keyword, while normal ones do not. For example, GetStaticIntField corresponds to getting the value of a static integer attribute, while GetIntField gets the value of an integer attribute of a normal object. Attribute-related set methods are of the form SetXField, where X stands for the specific type, corresponding to the type in the previous type system, or Object in the case of complex objects, as in SetObjectField. Accessing a property is simply a matter of replacing the prefix Set with Get. For static properties, a fixed Static is added between Set and X, i.e. SetStaticIntField. Method calls are prefixed with Call followed by the type of return value, in the form of CallXMethod. Here X stands for the return value. For example, CallVoidMethod calls a method of an object whose return value is of type void. The equivalent static method is Static between Call and X, as in CallStaticVoidMethod. Passing data to the Java world #Passing data to the Java world requires even more patience. Because we need to keep constructing objects, combining them, and setting properties. And each of these is a form of access to the Java object above.\nConstructing Java objects #C/C++ constructs Java objects and calls methods similarly. However, there are still a lot of details worth paying attention to. According to the previous method, we construct the object, first we need to know the id of the constructor method, and to get the id, we need to get jclass, the name and signature of the constructor method. We know that in the Java world, the constructor method has the same name as the class, but this is not the case in C/C++, it has a special name - \u0026lt;init\u0026gt;, note that \u0026lt;\u0026gt; can\u0026rsquo;t be missing here. That means that no matter what the class is called, the name of its constructor is \u0026lt;init\u0026gt;. And the key point of the function signature is the return value, the return value of the constructor method is void which corresponds to the signature type V.\nPicking up on the previous example of the Person class, how do you construct a Person object.\nGet the jclass object by FindClass of JNIEnv. Remember to replace ' with /. Get the appropriate id of the constructor method as needed. i don\u0026rsquo;t define a constructor method, then the compiler will provide it with a constructor method with no parameters. That is, the function signature is ()V. Call GetMethodID of JNIEnv to get the id. Call NewObject of JNIEnv to create the object, remember to pass the constructor parameter. I don\u0026rsquo;t need to pass it here. To summarize, this creation process is similar to the following example\nauto cls=env-\u0026gt;FindClass(\u0026#34;me/hongui/demo/Person\u0026#34;); auto construct=env-\u0026gt;GetMethodID(cls,\u0026#34;\u0026lt;init\u0026gt;\u0026#34;,\u0026#34;()V\u0026#34;); auto age=env-\u0026gt;GetFieldID(cls, \u0026#34;age\u0026#34;, \u0026#34;I\u0026#34;); auto name=env-\u0026gt;GetFieldID(cls, \u0026#34;name\u0026#34;, \u0026#34;Ljava/lang/String;\u0026#34;); auto p=env-\u0026gt;NewObject(cls,construct); auto nameValue=env-\u0026gt;NewStringUTF(\u0026#34;ZhangSan\u0026#34;); env-\u0026gt;SetIntField(p,age,18); env-\u0026gt;SetObjectField(p,name,nameValue); return p The above example has an interesting point, in fact the example creates two Java objects, one is Person object and the other is String object. Since the probability of a String exit is too high in programming, JNI provides this easy way. Also special is the creation of array objects. And because the type of the array is uncertain, there are multiple versions of the creation method, such as NewIntArray for creating an integer array. The method signatures are also quite regular, all in the form of NewX Array, where X stands for the type of the array, and all of these methods take one parameter, the size of the array. Since we are mentioning arrays, the methods for setting arrays have to be mentioned. There are methods for setting the value of an array element, in the form of SetXArrayRegion, such as SetIntArrayRegion which sets the value of an integer array element. Unlike the Java world, these methods support setting multiple values at the same time. The signature of an integer array looks like this - void SetIntArrayRegion(jintArray array,jsize start, jsize len,const jint* buf) The second parameter represents the start index of the set value, the third parameter is the number, and the fourth argument is a pointer to the true value. The rest of the types are similar.\nTake data access a step further #There are times when we don\u0026rsquo;t access an object when we call a native method, but sometime in the future. This is well realized in the Java world, where there is always a suitable class to hold the object reference passed in during this call, and it can be used directly at a later time. Is it the same in the native world? It\u0026rsquo;s the same in terms of usage flow, but it\u0026rsquo;s very different in terms of implementation.\nThe Java world has GC, which means that after passing some temporary object X to some object Y, the life cycle of X is transferred to Y, and X is not destroyed at the end of the call, but is recycled together with Y when Y is recycled. This approach is fine in the pure Java world, but when we pass this temporary object X to the native world and try to get it to work as it does in the Java world, the application crashes, reporting the error JNI DETECTED ERROR IN APPLICATION: native code passing in JNI DETECTED ERROR IN APPLICATION: native code passing in reference to invalid stack indirect reference table or invalid reference: 0xxxxx. Why does the same operation work in Java but not in native? The root of the problem is Java\u0026rsquo;s GC, which can determine whether an object needs to be marked as garbage through various garbage detection algorithms. In the native world, there is no GC, so in order not to cause memory leaks, you have to adopt the strictest policy, where the native method is called by default is where the Java object is used. So at the end of the scope of the native method call, the temporary object is marked as garbage by the GC, and if you want to use it again later, it may already be recycled. Luckily, the powerful JNIEnv class also provides methods for us to change this default strategy - NewGlobalRef. All an object needs to do is tell the JVM that it wants to live a little longer in this way, and the JVM will not mark it as garbage when performing garbage detection, and the object will live on. In until DeleteGlobalRef is called.Here NewGlobalRef, DeleteGlobalRef are one-to-one correspondence, and it is better to call DeleteGlobalRef to free memory when the object is no longer needed to avoid memory leaks.\nSummary #JNI development will involve knowledge of Java and C/C++ development, in the C/C++ implementation of JNI, the basic idea is to use C/C++ syntax to write Java logic, that is, everything for the service of Java.JNI development process, the main two issues to be dealt with, function registration and data access.\nFunction registration is recommended to use dynamic registration, use RegisterNatives of JNIEnv to register the function in JNI_OnLoad function, pay attention to keep the consistency of Java\u0026rsquo;s native methods and type signatures, and don\u0026rsquo;t forget to prefix the prefix L, suffix ; for composite types, and replace . for /.\nData access first needs to determine the access period, objects that need to be accessed in multiple places or at different times, remember to use NewGlobalRef to prevent the object from being recycled, and of course remember DeleteGlobalRef. To access an object, you need to get the id of the object and then determine the access method based on the type of access. Setting a property is usually in the form of SetXField and getting the value of a property is usually in the form of GetXField. To call a method, you need to determine the calling method based on the type of the return value, usually in the form of CallXMethod. Of course, all these are for normal objects, if you need to access static properties or methods, you add Static in front of the normal version of X. All Xs here refer to types, except for basic types, where Object is substituted.\nWhen registering functions and accessing data, one of the things you need to keep an eye on is the data type; C/C++ data types, except for the basic types, cannot be passed directly to Java, but need to be passed by creating an object. The general object creation method NewObject can create any object, and there are quick methods NewStringUTF and NewXArray for strings and arrays, which are frequently used. These two methods are essential for passing strings and arrays to Java.\nThis all,we will see you in the next post!\n","date":"12 September 2021","permalink":"/en/post/Android-JNI-development-introduction.html","section":"Posts","summary":"What is JNI #The full name of JNI is Java Native Interface, and as the name suggests, it\u0026rsquo;s a programming method that solves the problem of Java and C/C++ calling each other. It really only solves two aspects of the problem, how to find and how to access. Figure out these two topics and we have learned JNI development.","title":"A introduction to Android JNI"},{"content":"","date":null,"permalink":"/en/tags/cmake/","section":"Tags","summary":"","title":"CMake"},{"content":"Preface #CMake is a build tool, through which you can easily create cross-platform projects. It is usually used to build a project in two steps: generating a project file from the source code, and building the target product (which may be a dynamic library, a static library, or an executable program) from the project file. One of the main advantages of using CMake is that in the multi-platform or multi-people collaborative projects, developers can make their own preferences to make the choice of IDE, not subject to the influence of other people\u0026rsquo;s project configuration, it is a bit like a cross-platform IDE, through which the configuration of the relevant settings, you can be in multiple platforms seamlessly, improve development efficiency.\nSimplest CMake project #Project setup #A project managed with CMake will usually contain a CMakeLists.txt file in the project root directory, but of course subdirectories may also be present, which we\u0026rsquo;ll talk about later. Let\u0026rsquo;s start with the simplest project. Here is an example of the simplest project:\nCMakeProject | CMakeLists.txt | main.cpp This is the complete runnable minimal project. In order, let\u0026rsquo;s look at what\u0026rsquo;s in the file\nCMakeLists.txt\n# Set the version number cmake_minimum_required(VERSION 3.10) # Set the project name project(CMakeProject) # Setting up product and source code associations add_executable(${CMAKE_PROJECT_NAME} main.cpp) Description:\nCommands in CMake are not case-sensitive Comments beginning with `#' Referencing variable syntax ${variable name} So there are really only three lines of valid content in the document.\ncmake_minimum_required(VERSION 3.10) sets the minimum version supported by CMake. VERSION is the parameter name, followed by the version number. Note that the parameter name and parameters are separated by whitespace, not commas, or you will get an error. project(CMakeProject) CMake string can be with or without quotes, the effect is the same, this line is configured with the project name, such as the generation of Visual Studio project name is based on this name. add_executable(${CMAKE_PROJECT_NAME} main.cpp) is the real management of the source code and the target product of the place, here we use the reference variable writing, and the file does not define the variable, that this variable exists in CMake, in CMake there are a lot of predefined variables, we can be directly referenced in this way, the above writing is the name of the project is set to the product of the name, of course, you can also fill in the string directly, to take another name is fine. The latter main.cpp is used to generate the source path of the product, which is the most flexible part of CMake. This is the most flexible part of CMake. The source path can be various, it can be found out, written directly, relative path, absolute path, etc. If you have more than one source code, you can use it. ** If you have more than one source code, you can separate them with blanks and write them in order. In the configuration file above, we configured its source file as main.cpp, through which we want to generate an executable program with the same simple content:. #include \u0026lt;iostream\u0026gt; int main() { std::cout\u0026lt;\u0026lt;\u0026#34;hello CMake\u0026#34;\u0026lt;\u0026lt;std::endl; return 0; } Project compilation and execution #Now that the preparations are done, we\u0026rsquo;re going to use CMake to generate the executable.\nThe first step is of course to install CMake la, this is the download address !Download, according to their own platform to choose to download can be installed after the completion of the need to add it to the environment variables, so that we can easily use anywhere. After installing CMake, open the command line tool and go to the root directory of the project you just created, i.e. to the directory where CMakeLists.txt and main.cpp are stored, and prepare to generate the project in the next step.\nUsually in order not to affect and pollute the current working environment, we will choose to create a new directory to store the generated project files, the following I mainly Windows platform as the main platform to explain, other platforms are basically the same.\nmkdir build # Create a folder to store the project files; cd build # Switch the cmake working directory. cmake ... # Generate project files; After the execution of these three steps, we can see in the build folder has been generated inside a Visual Studio project, we can directly use Visual Studio to open the project, according to our habits to perform compilation and debugging. Of course, if you want to generate the fastest executable, I still recommend using CMake.\nTo perform a build with CMake, simply build on the previous step (i.e., you\u0026rsquo;ve already successfully performed the three steps above) by executing another command cmake --build . and you\u0026rsquo;re done. Remember to include the third period, which means that CMake builds in the current working directory. If everything went well in the above four steps, then we can see the executable file named after the first parameter of add_executable in the build/debug directory (in this case CMakeProject.exe), and we can execute it by double-clicking or dragging it to the command line.\nExtension the project #In the previous example, to generate the project file, we used two commands, in fact, here it can be done directly with one command - cmake build -S . -B build. The meaning of this command is to use the current path as the working path and the build directory as the build directory to generate the project file, that is, we don\u0026rsquo;t need to create the build folder manually. The -S parameter configures the source path and -B configures the build path.\nIn addition, since CMake does not have a cleanup method, every time we change CMake\u0026rsquo;s configuration (i.e., add or remove code from CMakeLists.txt) and need to regenerate the project file, we need to manually clean up the generated directory to make sure that it\u0026rsquo;s empty; if we don\u0026rsquo;t do this, the project may fail to be generated or the new configuration may not work. If you only change the source code, you don\u0026rsquo;t need to regenerate the project, just do the fourth step. Although the above operation is simple enough, but considering the long-term modification and validation needs, it is still too cumbersome and boring, especially to repeatedly switch the working directory, which is still rather annoying. So I recommend using batch processing to complete these operations. Combining the steps of cleaning up the generated directory and switching working directories, the final batch file may look like this\n@echo off rd /s /q build mkdir build cd build cmake ... cmake --build . cd debug CMakeProject cd ... /... Explain in order.\nThe first line turns off the command line\u0026rsquo;s echo, because we don\u0026rsquo;t want its echo to interfere with CMake\u0026rsquo;s message output in a way that causes unnecessary confusion, and also because usually we only care if it ends up doing its job rather than looking at what it\u0026rsquo;s doing.\nThe second line uses the Windows command for deleting folders (rmdir on Linux and MacOS), /s is to configure it to clear all the contents of the folder, including subfolders, without which the command will fail, and /q is to allow the command to execute the deletion directly without requiring us to manually confirm it, which is a very important parameter, as we would need to confirm the deletion of the folders one by one, completely defeating the purpose of automation. This parameter is very important, otherwise we need to confirm the deletion one by one, which completely defeats the purpose of automation. Then the next four sentences are what we talked about above, without further ado.\nComing all the way to the penultimate sentence, here I\u0026rsquo;ve written the name of the executable directly (you need to replace it with your own), in order to run the executable directly after the compilation is complete, which is useful for some applications that generate files.\nAt the end of the execution, then cut the directory back to the root directory of the project, this is the role of the last line, because we compile again has switched the directory to the generated directory, and the compiled executable file is in the generated directory of the subdirectory, so back to the root directory, we need to fall back twice, this is to ensure that the next time we can triumph in the execution of the batch processing key.\nSave the above as a file ending in bat, and then next time you can just type the bat file name at the command line to finish generating and building at once, it\u0026rsquo;s just awesome. This is all we need to know about CMake projects. Of course the actual project is far more complex than this, next I will use the pitfalls I have stepped on as a basis to increase the complexity of the project one by one, and slowly develop an understanding of CMake\u0026rsquo;s workflow.\nMulti-source projects #Personal insights #Before I start, let me talk about my understanding of the CMake project or CMakeLists.txt file. We can\u0026rsquo;t understand a configuration in isolation, we need to categorize the commands and even distill its core working pattern. I am using the compilation and linking of c++ files as a clue to sort it out. We all know that for a c++ source file to generate executable code, it needs three steps\nPreprocessor processing, copying the contents of header files to source files, macro replacement, etc; The compiler compiles the source files into .o object files; The linker takes .o files and other libraries as input and links to generate executables. It is much easier to understand CMake along these lines. If CMake reports an error, we can use the information to find out which phase of CMake is causing the problem, and then quickly find a solution. In addition, we can also use this information to categorize the CMake configuration, my own understanding of the rough categorization is as follows.\nConfigure CMake basic information: cmake_minimum_required; Source code management: file, aux_source_directory; Library-managed: find_libraray; Header file management: include_directories; For linkbase management: link_directories; Sub-project management: add_subdirectory; For generator management: add_executable, add_library; Of course, these are only a very small part of the picture, but they provide a better direction for understanding and searching for ideas to solve the problem.\nCMake manages subdirectories #Many times we introduce third-party packages to reduce duplicate coding efforts, and usually such code we need to put in other directories, so I created a new subdirectory to simulate the stored third-party code. For this case, we have two forms of inclusion - sub-modules and sub-directories.\nLet\u0026rsquo;s start with the simpler subdirectories. A subdirectory means that the third-party code is treated as part of our code and is merged and compiled together, in a way that makes our project look more compact. For example, the following project structure\nCMakeProject | auto.bat | CMakeLists.txt //Modify | main.cpp //modify | \\---3rd //Added lib.h I created a new subfolder to simulate the third party code, now let\u0026rsquo;s introduce it into main.cpp, compile it, and we\u0026rsquo;ll see that an error is reported, with the message fatal error C1083: Unable to open include file: \u0026quot;lib.h\u0026quot;: No such file or directory, which is normal. Combine this with the example I gave above. This error message is related to header files. Looking at the CMake documentation, I found out that CMake has an include_directories directive, which means to add the directory of the file header in order for CMake to find the header files. So I added include_directories(3rd) to the CMakeLists.txt file and ran the compile again and the project ran correctly. Take a look at the main.cpp at this point.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;lib.h\u0026gt; int main() { int a=1,b=1; std::cout\u0026lt;\u0026lt;\u0026#34;hello CMake\u0026#34;\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;\u0026#34;a + b = \u0026#34;\u0026lt;\u0026lt;sum(a,b)\u0026lt;\u0026lt;std::endl; return 0; } Note: There is a one-to-one correspondence between include_directories and include in the cpp, i.e., if the directory configured in include_directories is . (the current directory, CMake does not add the current directory to the include path), then the include of the corresponding cpp should be written in the form of 3rd/lib.h, which simply means that include_directories is set to the root of the include directory. The other case is submodules.\nCMake management submodule #Submodule means that the module can be compiled separately and provided separately for other libraries to use, instead of being symbiotic with the main project, which applies to the case where the coupling with the main module is not too big. In order to satisfy this condition, we modify the directory structure to the following one\nCMakeProject | auto.bat | CMakeLists.txt //Modify | main.cpp | \\-3rd CMakeLists.txt //added lib.cpp //added lib.h //modify I changed the functions in lib.h to declarations, and the implementation is in the lib.cpp file. The biggest change was the creation of a new CMakeLists.txt file in the 3rd directory, which manages all the source files in the 3rd directory in a unified way (in case there are a lot of files, this is a simulation), and the use of add_library to package the 3rd directory into sub-modules.\nproject(sum) add_library(${PROJECT_NAME} lib.cpp) add_library can also specify the build type between the name and the source code, the default is STATIC, which is a static library, if you want to build a dynamic library you need to manually specify SHARED (add_library(${PROJECT_NAME} SHARED lib.cpp)).\nThe important changes come from CMakeLists.txt in the main directory.\n# Set the version number cmake_minimum_required(VERSION 3.10) # Set the project name project(CMakeProject) # Specify 3rd as the lookup directory for include include_directories(3rd) # Submodules add_subdirectory(3rd) # Setting up product and source code associations add_executable(${PROJECT_NAME} main.cpp) target_link_libraries(${PROJECT_NAME} sum) Added add_subdirectory, which is used to compile the source code from a specified directory as a module, provided there is a CMakeLists.txt file in that directory. Another change is the addition of target_link_libraries, which is used to link submodules into the main module; without it, linking would result in an error error LNK2019: unresolved external symbol. The name of the module needs to be the same as the first parameter of add_library in the submodule.\nCross-compilation #While the complexity of the project in the previous example was shown in the multiple directories and source code, the main complexity of the project in the process of cross-compiling with CMake is shown in the environment configuration. Although CMake can be used to cross-compile with little or no modification to CMakeLists.txt, newcomers are often overwhelmed by unfamiliar configurations and try to find an easy way to configure them with a single click. It is true that there is no such shortcut for CMake, but once we understand the essence of ** cross-compilation is the process of configuring property values correctly. However, once we understand that cross-compiling is the process of correctly configuring property values, the problem becomes clear. So, the questions above become familiar - what properties need to be configured, what are the appropriate values for those properties, how are those values passed to CMake, etc., and that\u0026rsquo;s what cross-compilation is all about. As mentioned before, CMake has a lot of preset variables, and we need to find some of these preset variables, set some values, and then let CMake do its job according to these configurations, and that\u0026rsquo;s what we need to do next. Below I will illustrate this process with an example of cross-compiling Android for Windows.\nPrepare #On Windows platform, Visual Studio will be used as the compiler for C, C++ by default, which may report errors for compiling libraries for Android. So you need to use -G \u0026quot;Unix Makefiles\u0026quot; to change this behavior when executing cmake command. But that\u0026rsquo;s not enough, because CMake compilation is required to specify the compiler. The C,C++ compiler on Android is usually provided in the form of NDK, so we need to download the NDK, which provides us with two tools at the same time, one is the compiler, and the other one is android.toolchain.cmake, which is also the file composed of CMake commands, which specifies a lot of preset values for cross-compilation, which can greatly simplify the compilation process. This is also a CMake file, which specifies a lot of presets for cross-compilation, which can greatly reduce our work.\nWrite compilation scripts #As mentioned earlier, cross-compiling is all about changing the CMake preset, and there are two ways to change this preset that we\u0026rsquo;re going to use in combination. One is through the android.toolchain.cmake file provided by the NDK. The android.toolchain.cmake file sets most of the values, but it is also very flexible and has a lot of room for configuration. Therefore, depending on the user\u0026rsquo;s needs, we also need to pass some values dynamically when executing CMake commands in order for CMake to do its job correctly. This is another way - options. Passing options will start with -D followed by some CMake predefined variable Since there are a lot of options and most of them are complex, it\u0026rsquo;s better to document and modify them through script files. Below are just a few of the options that need to be specified to compile Android code on the Windows platform, and I\u0026rsquo;ll go over the necessary configurations one by one.\n-DCMAKE_SYSTEM_NAME=Android This configuration tells CMake that it needs to generate libraries for the Android platform, i.e., perform cross-compilation. The -DANDROID_ABI=x86 configuration tells CMake to generate libraries for the applicable architectural platforms. Readers familiar with Android development should not be unfamiliar with the supported values will change according to the changes in the NDK, such as the early armeabi has been removed in the NDK r17, now there are four mainstream armeabi-v7a, arm64-v8a, x86, x86_64. Just replace the values as needed. -DANDROID_PLATFORM=android-28, this value is not really necessary as there are preset values, but it is necessary to specify one for controllability. It is used to determine the minimum system version supported by the library. -DCMAKE_TOOLCHAIN_FILE=C:/Users/Leroene/AppData/Local/Android/Sdk/ndk/21.0.6113669/build/cmake/android.toolchain.cmake, which is the above mentioned preset file. Note that there are multiple files with this name in the NDK, and if you specify them incorrectly, you may get CMake errors, so my experience has been to change the version number (C:/Users/Leroene/AppData/Local/Android/Sdk/ndk/21.0.6113669) and the paths in front of it, and leave the paths behind it unchanged. The latter stays the same. -DCMAKE_MAKE_PROGRAM=C:/Users/Leroene/AppData/Local/Android/Sdk/ndk/21.0.6113669/prebuilt/windows-x86_64/bin/make The last argument specifies the path to the make program path, since we are specifying the code that generates the make project and Windows usually does not have a make executable, we need to let CMake find the make file in order to complete the compilation. My experience here is also to keep the later unchanged, modify the earlier, and keep the version consistent to avoid bugs. -DCMAKE_BUILD_TYPE=Release to specify the build type, which should be common enough. At this point all the configurations for cross compiling Android libraries for Windows have been explained. Let\u0026rsquo;s have a look at its complete example\n@echo off rd /s /q build mkdir build cd build cmake -G \u0026#34;Unix Makefiles\u0026#34; ^ -DCMAKE_TOOLCHAIN_FILE=C:/Users/Leroene/AppData/Local/Android/Sdk/ndk/21.0.6113669/build/cmake/android.toolchain.cmake ^ -DCMAKE_MAKE_PROGRAM=C:/Users/Leroene/AppData/Local/Android/Sdk/ndk/21.0.6113669/prebuilt/windows-x86_64/bin/make ^ -DANDROID_PLATFORM=android-28 ^ -DCMAKE_SYSTEM_NAME=Android ^ -DANDROID_ABI=x86 ^ -DCMAKE_BUILD_TYPE=Release ^ ... /3rd cmake --build . As you can see from the above, these options are all followed by a ^ symbol, which is not part of cmake, it is just written this way for our reading convenience, this is the command line break used for batch processing on Windows platform, its function is to tell the command parser that the command is not yet finished, and continue to be parsed down the line, this function is equivalent to \\ on Linux,MacOS This function corresponds to \\ on Linux and MacOS. Now that you have this configuration, how do you use it? It\u0026rsquo;s quite easy, just store these commands in the android.bat file, switch to the current directory in CMD, execute this file and you\u0026rsquo;ll find the static library file named libsum.a in the build directory. Next, let\u0026rsquo;s try to run in the emulator with this library file.\nUsing CMake in an Android project #In the Android platform, CMake is also used to manage jni projects, along with Gradle to complete the build. The biggest difference between this and a normal CMake project is that we usually need to reference multiple Android related libraries such as log, android, etc. These libraries are usually provided by NDK. These libraries are usually provided by the NDK, and we can just follow the default CMakeLists.txt file.\nDirectory structure #Next, for descriptive purposes, let\u0026rsquo;s take a look at the current directory structure (to avoid confusion, only the more representative files are listed here)\nCMakeProject │ android.bat │ CMakeLists.txt │ main.cpp │ ├óΓé¼╦£3rd │ CMakeLists.txt │ lib.cpp │ lib.h │ └─Android │ build.gradle │ ├─app │ │ build.gradle │ │ │ ├─libs │ └─src │ ├─main │ │ │ AndroidManifest.xml │ │ │ │ │ ├─cpp │ │ │ CMakeLists.txt │ │ │ native-lib.cpp │ │ │ │ │ ├─java │ │ └─me │ │ └─hongui │ │ └─cmakesum │ │ │ MainActivity.kt │ │ │ │ │ ├─jniLibs │ │ └─x86 │ │ │ libsum.a A new Android subdirectory has been created under the root of the original directory, which is an Android C++ project, so it has an extra cpp directory compared to other normal Android projects, and the main modifications we\u0026rsquo;ll make later on happen in that directory.\nThe original root directory, in order not to add complexity, exists only as a function of generating static libraries, so there are no modifications compared to the example above.\nBuild static libraries #First, let\u0026rsquo;s go back to the root directory. Use the android.bat batch in the root directory to generate static libraries that are available on Android, you can also modify the value of the -DANDROID_ABI option in the android.bat file to generate static libraries for other architectures, but this needs to correspond to the directories in the jniLibs directory, otherwise the link may fail. For example, the libsum.a file I generated is for the x86 architecture. Then you need to create a new x86 directory in the jniLibs directory, and then put libsum.a into that directory. This concludes the build of the static library.\nUsing static libraries #After putting the static libraries in place, we need to configure the build.gradle in the app directory and the CMakeLists.txt file in the cpp directory to complete the introduction of the static libraries.\nConfiguring Gradle #First, let\u0026rsquo;s talk about build.gradle, which is mainly concerned with modifying the ABI, because if you don\u0026rsquo;t specify it, the ABI generated by Gradle by default may not find the corresponding static library file to link to, which may lead to linking failure. The main changes in this file are as follows android { defaultConfig { externalNativeBuild { cmake { cppFlags \u0026quot;\u0026quot; abiFilters \u0026quot;x86\u0026quot; } } } } That is, specify the value of abiFilters as the same value as the static library you just built.\nConfiguring CMake #The CMakeLists.txt file is a bit more complicated, it needs to do two jobs, find the static libraries and static libraries\u0026rsquo; header files, and link the static libraries.\nfind header file #In the second part of the article we already knew about the include_directories command that lets CMake find header files, just set the parameter to the 3rd directory. It\u0026rsquo;s worth noting that CMake uses the current CMakeLists.txt file as its working directory, so to specify to the 3rd file we need to go all the way back in the directory to the root project, and end up with include_directories(... /... /... /... /... /3rd) configuration. Try to use relative paths, you can collaborate with multiple people without having to change the configuration.\nfind static library #The next step is to get CMake to find our static library. When it comes to libraries, it\u0026rsquo;s all related to add_library, the difference is just the parameters. When adding a library using source, we need to specify the name and source location of the library, whereas to reference a third-party library, we need to specify the name and type of the library, plus an IMPORTED indicator parameter to tell CMake that the library is imported. So there is a configuration like add_library(addSum STATIC IMPORTED).\nHowever, here we have only told CMake the name of the library, where the library is stored is not yet known, so we need another command to tell CMake where the library is stored. When it comes to configuration parameters, it\u0026rsquo;s usually the set_target_properties command, which can be called multiple times to set multiple configurations. set_target_properties(addSum PROPERTIES IMPORTED_LOCATION ${CMAKE_CURRENT_SOURCE_DIR}/... /jniLibs/${ANDROID_ABI}/libsum.a), the first parameter and the first parameter of the previous entry are one-to-one and can be taken at will. In fact, add_library is equivalent to generating a target product, and the first parameter is used to refer to such a product, which is why our set_target_properties is allowed to find the appropriate target setting properties. The second parameter is the standard way to write a configuration property, the third represents the property variable, and the fourth is the value of the property. The variable that configures the library path is IMPORTED_LOCATION, and the value has a pitfall here, as CMake under Android restricts the value to an absolute path, not a relative path. This is contrary to the original purpose of using CMake, fortunately, we have a few preset values that we can use, CMAKE_CURRENT_SOURCE_DIR is one of them, it represents the absolute path of the current CMakeLIsts.txt file, with this, and the directory fallback function, we can find any appropriate directory. At this point, a second problem arises, when there are multiple architectures with static libraries to configure, we introduce different directories, and there is a lot of duplication of configurations. Luckily, it helps to have ANDROID_ABI, which refers to a certain architecture that is currently being compiled, and as the compilation progresses, this value is set to the appropriate value, and is a one-to-one correspondence with the architecture being compiled. So, even though they are a bit strange, this gives me flexibility and simplicity.\nLinking static libraries #Now we have the header files and the libraries, but the compilation of C++ is divided into two steps, so far, our work has only done the compilation of things, not yet involved in the linking of things, of course, compared to the previous configuration, this is much simpler, undoubtedly is in the target_link_libraries command to add a parameter can be, such as\ntarget_link_libraries( native-lib ${log-lib} addSum ) Just yo note that the name corresponds one to one with the name configured during add_library.\nUse in source code #After a long wait, we are now able to introduce the addsum header file in the native-lib.cpp file and use the functions inside to get the job done. I intend for the function to return a string containing the result of the addition operation. The final implementation is as follows\n#include \u0026lt;jni.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;lib.h\u0026gt; extern \u0026#34;C\u0026#34; JNIEXPORT jstring JNICALL Java_me_hongui_cmakesum_MainActivity_stringFromJNI( JNIEnv* env, jobject /* this */) { std::string hello = std::to_string(sum(1,1)); return env-\u0026gt;NewStringUTF(hello.c_str()); } At this point, click the run button on the toolbar and we can finally see the results of our static library work in the Android emulator.\nExtension #In fact, besides the way of referencing static libraries, we can also directly reference the source code by configuring the CMakeLists.txt file, which allows us to customize the source code anytime, anywhere, but it also slows down the compilation speed and may increase the complexity of CMakeLists.txt. So I still recommend the direct static library approach.\nSummary #CMake in fact, there are many, many commands, we are involved here is only a very small part. However, I think that understanding CMake has these contents almost on it, the subsequent need to target learning on the line. Learning a technology, we must not be greedy, greedy for details. First of all, we must grasp the main, clear vein, the details of the latter is a matter of water to the drain. For CMake, I think it is the C++ code compiled into a binary process as the main trunk is enough. Where the source code comes from, where the header files are, where the library files are, how to organize the compilation, what libraries are involved in linking, what products are generated, and some general operations to complete these tasks, copying files ah, directory information ah, etc., a collection of these operations constitute the main body of CMake. In addition, CMake is really just a build tool, it is not a compiler or linker, and some problems may involve not only cmake, but also the compiler and linker. Of course, these are all issues that you may encounter later on, when you know more about it.\n","date":"9 August 2021","permalink":"/en/post/Personal%20understanding%20and%20useage%20of%20CMake.html","section":"Posts","summary":"Preface #CMake is a build tool, through which you can easily create cross-platform projects. It is usually used to build a project in two steps: generating a project file from the source code, and building the target product (which may be a dynamic library, a static library, or an executable program) from the project file.","title":"Personal understanding and useage of CMake"},{"content":"","date":null,"permalink":"/en/tags/c/c++/","section":"Tags","summary":"","title":"C/C++"},{"content":"","date":null,"permalink":"/en/categories/c/c++/","section":"Categories","summary":"","title":"C/C++"}]